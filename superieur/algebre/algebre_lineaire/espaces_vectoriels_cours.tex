\documentclass{book}
\usepackage{jlq2eams}

\begin{document}

%TODO proof  et rajouter des exemples

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Espaces vectoriels}



\begin{Ex}[$\vect{x}\in \R^2$]
Tout d'abord, commençons par les vecteurs du plan :\\
\begin{tabular}{p{3cm}|p{4cm}|p{4cm}|p{4cm}}
&Vecteur géométrique  &   Vecteur  numérique  &   Vecteur  algébrique       \\  \hline
Représentation&\includegraphics[width=3cm]{espace_vectoriel_vecteur.png} & $\begin{pmatrix}
2\\1
\end{pmatrix}$ & $\vect{u}= 2 \vect{e}_1 + 1 \vect{e}_2 $  \\\hline
Multiplication par un scalaire & \includegraphics[width=4cm]{espace_vectoriel_vecteur_homo.png} & $\begin{pmatrix}
-1\\-0,5
\end{pmatrix}=-0.5.\begin{pmatrix}
2\\1
\end{pmatrix}$  &  $\vect{v}=-0.5.\vect{u}$ \\\hline
Addition  & \includegraphics[width=0.15\textwidth]{espace_vectoriel_vecteur_sum.png} & $\begin{pmatrix}
1\\2
\end{pmatrix}=\begin{pmatrix}
2\\1
\end{pmatrix}+\begin{pmatrix}
-1\\1
\end{pmatrix}$&$ \vect{w}= \vect{u}+\vect{v}$
\end{tabular}\\
\end{Ex}
Du fait de l'équivalence\footnote{Il y a des limites à cette équivalence. La représentation géométrique est uniquement pertinente dans le plan et l'espace. La représentation numérique est limitée aux espaces vectoriels de dimension finie.} entre ces trois représentations,  géométrique,  numérique et algébrique, tout ce qui est vrai ou faux pour l'un l'est aussi pour l'autre. Savoir passer d'une représentation à l'autre est essentiel pour bien comprendre l'algèbre linéaire. 
\begin{Ex}[Exemples d'ensembles de vecteurs : $E=\{\vect{x}\}$]
Il existe de très nombreux ensembles  où il est possible d'effectuer une addition et une homothétie soit une combinaison linéaire, par exemples :
\begin{itemize}
\item l'ensemble des n-uplet réels : $\vect{x}=(x_{1},x_{2},\ldots ,x_{n})$ et $E=\R^n$ et , où chaque $x_{i}$ est un réel,
%jeu vidéo: rendu d'objets dans une scène (jeux vidéos) et un vecteur d'appréciation de films 
\item l'ensemble des matrices carrés réels : $\vect{x}=\begin{pmatrix}
a_{1,1} & a_{1,2} & \cdots & a_{1,n}\\
a_{2,1} & a_{2,2} & \cdots & a_{2,n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n,1} & a_{n,2} & \cdots & a_{n,n}\\
\end{pmatrix}$ et $E=\mathcal{M}_{n}(\R)$ , où  chaque $a_{i,j}$ est un un réel,
\item l'ensemble des solutions d'une équations différentielles linéaire d'ordre 1 homogène : $\vect{x}=f$ une fonction $\mathcal{C}^1$ tel que  $f'+a_{0}f=0$ et $E=\{f\in C_1 :  f'+a_{0}f=0\}$,
\item l'ensemble des polynômes réels : $\vect{x}= a_{0}+a_{1}X^{1}+a_{2}X^{2}+\dots +a_{n}X^{n}$ et $E=\R[X]$,
\item l'ensemble des suites réels : $\vect{x}=(u_{n})_{n\in \mathbb {N} }$ et $E=\R^{\N}$,
\item etc.
\end{itemize}
\end{Ex}
Une stratégie efficace pour étudier ces ensembles est :
\begin{enumerate}
\item de définir une structure algébrique abstraite constituée de propriétés partagés par tous les ensembles : cette structure s'appelle \defi{l'espace vectoriel} et permet d'effectuer des combinaisons linéaires,
\item de démontrer des énoncés sur cette structure  : ce qui est vrai ou faux dans cette structure  l'est aussi pour tous les cas particuliers. 
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Structure algébrique}
\begin{Df}[Loi de composition interne : $\vect{x} \bigtriangleup \vect{y}$  ]
Soit $A$ un ensemble. Une \defi{loi de composition interne}, $\bigtriangleup$, est une application qui, à deux éléments de $A$, associe un élément de $A$ :
$$ \Fonction{\bigtriangleup}{A×A}{A}{(x,y)}{x \bigtriangleup y}.$$
\end{Df}
\begin{Df}[Propriétés]
On dit que $\bigtriangleup$ 
\begin{enumerate}
\item est \defi{associative} : si $\in(x,y,z)\in A^3$, $x \bigtriangleup (y \bigtriangleup z) = (x \bigtriangleup y) \bigtriangleup z$.
  On ne considèrera que des loi associatives.
\item
est \defi{commutative} : si $\forall(x,y)\in A^2$, $x \bigtriangleup y = y \bigtriangleup x$;
\item admet \defi{un élément neutre} si $\exists e\in A$ tel que $\forall x\in A$, $x \bigtriangleup e = e \bigtriangleup x = x$.
  Il existe au plus un élément $e$ vérifiant cette propriété, et on l'appelle \defi{le neutre}  de la loi $\bigtriangleup$.
\item
est \defi{symétrique} (ou \defi{inverse} si loi est $\times$ , ou \defi{opposé} si la loi est $+$)
  Si $\bigtriangleup$ est une loi associative qui admet un neutre $e$, et si $x\in A$, on appelle  de $x$ pour la loi $\bigtriangleup$ tout élément $x'\in A$ tel que $x \bigtriangleup x' = x' \bigtriangleup x = e$.
  Si $\bigtriangleup$ est également associative, il existe au plus un élément $x'$ vérifiant cette propriété, et on l'appelle \defi{le} symétrique de $x$ pour la loi $\bigtriangleup$.
\end{enumerate}
\end{Df}
\begin{Df}[Groupe]
Un \defi{groupe} est un couple $(G,\bigtriangleup)$ où $G$ est un ensemble et $\bigtriangleup$ une loi de composition interne sur $G$ associative, admettant un neutre et pour laquelle tout élément de $G$ admet un symétrique pour la loi $\bigtriangleup$.
Un groupe est dit \defi{abélien} ou \defi{commutatif} si la loi $\bigtriangleup$ est de plus commutative.
\end{Df}
\begin{Ex}[Le Groupe $(\R^n,+)$ ]
La loi d'addition sur $\R^n$ est définie par 
$$ \Fonction{+}{\R^n\times\R^n}{\R^n}{(\vec{x}=(x_1,x_2,\dots,x_n),\vect{y}=(y_1,y_2,\dots,y_n))}{\vect{x}+\vect{y}=(x_1+y_1, x_2+y_2, \dots, x_n+y_n)}.$$

\begin{itemize}
\item  \defi{associative} : Soit $\vect{x}=(x_1,x_2,\dots,x_n),\vect{y}=(y_1,y_2,\dots,y_n),\vect{z}=(z_1,z_2,\dots,z_n)\in\R^n .$\\
 On a :
 \begin{align*}
 \vect{x}+(\vect{y}+\vect{z})&=(x_1,x_2,\dots,x_n)+\left((y_1,y_2,\dots,y_n)+(z_1,z_2,\dots,z_n)\right)\\
 &=(x_1,x_2,\dots,x_n)+(y_1+z_1, y_2+z_2, \dots, y_n+z_n)\\
 &=(x_1+y_1+z_1, x_2+y_2+z_2, \dots, x_n+y_n+z_n)\\
  &=(x_1+y_1, x_2+y_2, \dots, x_n+y_n)+(z_1,z_2,\dots,z_n)\\
  &=\left((x_1,x_2,\dots,x_n)+(y_1,y_2,\dots,y_n)\right)+(z_1,z_2,\dots,z_n)\\
  &=(\vect{x}+\vect{y})+\vect{z}
 \end{align*}
 \item  \defi{commutative} : Soit $\vect{x}=(x_1,x_2,\dots,x_n),\vect{y}=(y_1,y_2,\dots,y_n)\in\R^n .$\\
 On a :
 \begin{align*}
 \vect{x}+\vect{y}&=(x_1,x_2,\dots,x_n)+(y_1,y_2,\dots,y_n)\\
  &=(x_1+y_1, x_2+y_2, \dots, x_n+y_n)\\
  &=(y_1+x_1, y_2+x_2, \dots, y_n+x_n)\\
  &=\vect{y}+\vect{x}
 \end{align*}
 \item  \defi{élément neutre} : Soit $\vect{x}=(x_1,x_2,\dots,x_n)\in\R^n$\\
 Montrons que $\vect{0}=(0,0,\dots,0)$ est l'élément neutre\\
 On a :
 \begin{align*}
 \vect{x}+\vect{0}&=(x_1+0,x_2+0,\dots,x_n+0)\\
  &=(x_1, x_2, \dots, x_n)\\
  &=\vect{x}
 \end{align*}
  \item  \defi{symétrique} : Soit $\vect{x}=(x_1,x_2,\dots,x_n)\in\R^n$\\
 Montrons que $-\vect{x}=(-x_1,-x_2,\dots,-x_n)$ est l'opposé de $\vect{x}$.\\
 On a :
 \begin{align*}
 \vect{x}+(-\vect{x})&=(x_1,x_2,\dots,x_n)+(-x_1,-x_2,\dots,-x_n)\\
  &=(x_1-x_1, x_2-x_2, \dots, x_n-x_n)\\
  &=(0, 0, \dots, 0)\\
  &=\vect{0}
 \end{align*}
\end{itemize}
Donc $(\R^n,+)$ est un groupe commutatif.
\end{Ex}


\begin{Df}[Loi de composition externe : $\lambda.\vect{x}$] Soit $\K$ et $A$ deux ensembles. Une \defi{loi de composition externe}, $.$, est une application qui, à un élément de $\K$ et un élément de $A$, associe un élément de $A$ :
$$ \Fonction{.}{\K×A}{A}{(\lambda,x)}{\lambda. x} $$
\end{Df}
\begin{Ex}[$(\R^n,.)$]
La loi de multiplication sur $\R^n$ est définie par 
$$ \Fonction{.}{\R\times\R^n}{\R^n}{(\lambda,\vect{x}=(x_1,x_2,\dots,x_n))}{\lambda.\vect{x}=(\lambda.x_1, \lambda.x_2, \dots, \lambda.x_n)}.$$
Par exemple sur $\R^2$, $2.(1,-2)=(2,-4)$.
\end{Ex}

\begin{Df}[Corps $\K$ : $\R$ ou $\C$] Dans ce cours%\samepage\footnote{%\begin{tiny}
%Un \defi{corps} (commutatif) $(K,+,\times )$ est un ensemble muni de deux lois internes possédant les propriétés suivantes :
%\begin{itemize}
%\item $(K,+)$ est un groupe abélien, dont l'élément neutre est noté $0$ ;
%\item $(K\setminus \{0\},\times )$ est également un groupe abélien, dont l'élément neutre est noté $1$ ;
%\item $\times$ est distributive par rapport à $+$.
%\end{itemize}
%\textbf{Remarque} Lorsque le contexte est clair, on écrit souvent $\K$ au lieu de $(\K,+,×)$.\\
%\textbf{Exemples}
%\begin{itemize}
%\item le corps des réels $\R$, des complexes $\C$, des rationnels $\Q$;
%\item si $\K$ est un corps, le corps des fractions rationnelles à coefficients dans $\K$, noté $\K(X)$;
%\item $\Q [i] = \{a+ib:(a,b)\in \Q ^2\}$;
%\item le corps des entiers modulo un nombre premier $p$, noté $\Z/p\Z$.
%\end{itemize}
%}
, un corps $\K$ désigne soit l'ensemble des nombres réels $\R$ ou soit l'ensemble des nombres complexes $\C$. 
\end{Df}
\begin{Df}[Espace vectoriel : $\lambda\vect{x}+\mu\vect{y}$]
Soit $\K$ un corps.\\
Un \defi{$\K$-espace vectoriel} est un triplet $(E,+,.)$ où
$+$ est une loi de composition interne sur $E$ et
$.$ est une loi de composition externe sur $E$,
vérifiant les propriétés suivantes:
\begin{enumerate}
\item $(E, +)$ est un groupe commutatif;
\item la loi $.$ est compatible avec la structure de groupe $(E, +)$, i.e.  
 \begin{enumerate}
  \item $\forall(\lambda ,\mu )\in\K^2$, $\forall \vect{x}\in E$, $(\lambda +\mu ) . \vect{x} = (\lambda . \vect{x}) + (\mu . \vect{x})$;
  \item $\forall\lambda \in\K$, $\forall(\vect{x},\vect{y})\in E^2$, $\lambda . (\vect{x}+\vect{y}) = (\lambda . \vect{x}) + (\lambda . \vect{y})$;
  \item $\forall\vect{x}\in E$, $1_\K. \vect{x} = \vect{x}$;
  \item $\forall(\lambda ,\mu )\in\K^2$, $\forall\vect{x}\in E$, $\lambda . (\mu . \vect{x}) = (\lambda \mu ) . \vect{x}$.
  \end{enumerate}
\end{enumerate}
Un élément d'un $\K$-espace vectoriel est appelé un vecteur et est noté dans ce cours avec une flèche  $\vect{x}$. Un élément du corps $\K$ est un scalaire et est noté dans ce cours à l'aide d'une lettre grecque, $\lambda$.   
\end{Df}


\begin{Ex}

\begin{itemize}
\item les n-uplets $\K^n$ muni des lois usuelles, 
\item
  les matrices $\mathcal{M}_{n,p}(\K)$ muni des lois usuelles,
\item
 si $X$ est un ensemble et $E$ un $\K$-espace vectoriel, l'ensemble des fonctions $\mathcal{F}(X,E)$ muni des lois usuelles.
\end{itemize}
\end{Ex}
%\begin{Prop}[Structure de $\K $-espace vectoriel]
%$\MnpK$ possède une structure de $\K $-espace vectoriel. 
%\end{Prop}
\section{Construire des espaces vectoriels}
\subsection{Sous-espace vectoriel : $F\subset E$ et $F$ e.v.}
\subsubsection{Définition}
\begin{DfProp}[Sous espace vectoriel]
Soit $(E,+,.)$ un $\K $-espace vectoriel et $F$ une partie de $E$.
On dit que $F$ est un \defi{sous espace vectoriel} de $E$ si
\begin{itemize}
\item
  $F$ est non vide,
\item
  $F$ est stable par $+$, i.e.   $\forall \vect{x},\vect{y} \in F$, $\vect{x}+\vect{y}\in F$,
\item
  $F$ est stable par $.$ , i.e.   $\forall \lambda \in \K $, $\forall \vect{x} \in F$, $\lambda .\vect{x}\in F$.
\end{itemize}
Muni des lois induites, F est alors un espace vectoriel.
\end{DfProp}
\begin{Ex}
$F=\{(x,y)\in\R^2:x+2y=0\}$ \includegraphics[width=4.5cm]{espace_vectoriel_exemple_ssev.png} est un sous espace vectoriel de $\R^2$ 
car :
\begin{itemize}
\item \textit{non vide :}\\
$(0,0)\in \R^2$ car $0+2.0=0.$
\item \textit{stable par $+$ :}\\
Soit $\vect{x}_1=(x_1,y_1),\vect{x}_2=(x_2,y_2) \in F $ d'où $ x_1+2y_1=0$ et $ x_2+2y_2=0$.\\
Montrons que $\vect{x}_1+\vect{x}_2=(x_1+x_2,y_1+y_2)\in F$.\\
i.e. montrons que $(x_1+x_2)+2(y_1+y_2)=0$.\\
On a :
$$(x_1+x_2)+2(y_1+y_2)= x_1+2y_1 + x_2+2y_2 = 0+0 =0.$$
\item
  \textit{stable par $.$ :} \\
Soit $\lambda\in \R$ et $\vect{x}=(x,y)\in F $ d'où $ x_1+2y_1=0$ et $ x_2+2y_2=0$.\\
Montrons que $\lambda\vect{x}=( \lambda x,\lambda  y)\in F$.\\
i.e. montrons que $(\lambda x)+2(\lambda  y)=0$.\\
On a 
$$(\lambda x)+2(\lambda  y)= \lambda (x +2 y) = \lambda 0 =0.$$  
\end{itemize}
\end{Ex}

\begin{Prop}[Critère d'un sous-espace vectoriel]
Soit $E$ un $\K $-espace vectoriel et $F\subset E$.
$F$ est un sous espace vectoriel  de $E$ si et seulement si
\begin{itemize}
\item
  $\vect{0_E}\in F$;
\item
  $\forall \lambda  \in \K $, $\forall  \vect{x},\vect{y} \in F$, $\lambda .\vect{x} + \vect{y} \in  F$.
\end{itemize}
\end{Prop}
\subsubsection{Engendré par une famille finie : $\Vectt (\vec{x}_1,\dots,\vec{x_p})=\{\lambda_1. \vec{x_1}+\dots + \lambda_p. \vec{x_p} \}$ }

\begin{Df}[Famille finie]
Soit $E$ un $\K $-espace vectoriel.\\
Une \defi{famille finie} de vecteurs de $E$ est un $p$-uplet $\mathcal{F} = (\vect{x}_1,\dots,\vect{x_p})$ formée de vecteurs de $E$, où $p\in \N$.
\end{Df}
\begin{Df}[Combinaison linéaire]
Avec les mêmes notations, une \defi{combinaison linéaire} de la famille $\mathcal{F}$ est un vecteur $\vect{x} \in E$ de la forme $\vect{x} = \lambda_1. \vect{x_1}+\dots + \lambda_p. \vect{x_p}$ où $\lambda_1,\dots,\lambda_p \in  \K$.\\
Les scalaires $\lambda_1,\dots,\lambda_p$ sont appelés \defi{coefficients} de la combinaison linéaire.\\
On note \defi{$\Vectt (\mathcal{F})$} l'ensemble des combinaison linéaires de la famille $(\vect{x}_1,\dots,\vect{x_p})$.\\
$$\Vectt (\mathcal{F})=\{ \lambda_1. \vect{x_1}+\dots + \lambda_p. \vect{x_p} : \lambda_1,\dots,\lambda_p \in  \K \}.$$
Par convention, $\Vectt(\emptyset)= \{\vect{0}_E\}$.
\end{Df}
\begin{DfProp}[Espace engendré]
Soit $E$ un $\K $-espace vectoriel et $(\vect{x}_1,\dots,\vect{x_p})$ une famille de vecteurs de $E$.\\
L'ensemble $\Vectt(\vect{x}_1,\dots,\vect{x_p})$ est un sous espace vectoriel  de $E$, appelé \defi{espace engendré} par la famille $(\vect{x}_1,\dots,\vect{x_p})$.
Il s'agit du plus petit (pour l'inclusion) sous espace vectoriel  de $E$ contenant $\vect{x_1},\dots,\vect{x_p}$.
\end{DfProp}
\begin{Ex}[Droite vectoriel]
Lorsque que $p=1$ avec $ \vect{x} \neq \vect{0}$, $\Vectt(\vect{x}) = \{\lambda .\vect{x} : \forall \lambda  \in  \K  \}$
est la \defi{droite vectorielle} engendrée par $\vect{x}$. On la note $\R \vect{x}$.\\
Une droite vectorielle dans $\R ^2$ est 
\begin{center}
\includegraphics[width=6cm]{espace_vectoriel_droite.png}
\end{center}
\end{Ex}
\begin{Ex}[Plan vectoriel]
Lorsque que $p=2$ avec $ \vect{x_1}$ non colinéaire à $\vect{x_2}$, $\Vectt (\vect{x_1},\vect{x_2}) = \{\lambda .\vect{x_1}+\mu.\vect{x_2} : \forall \lambda ,\mu \in  \K  \}$
est le \defi{plan vectorielle} engendrée par $(\vect{x_1},\vect{x_2})$. On le note $\R \vect{x_1}+\R \vect{x_2}$.\\
Un plan vectorielle dans $\R ^3$  est 
\begin{center}
\includegraphics[width=6cm]{espace_vectoriel_plan.png}
\end{center}
\end{Ex}
\subsubsection{Intersection $F_1\cap F_2$}

\begin{Prop}
Soit $E$ un $\K $-espace vectoriel, $F_1, \dots, F_p$ des sous espaces vectoriels de $E$.\\
Alors l'intersection $\cap_{i=1}^p F_i$ est également un sous espace vectoriel.
\end{Prop}
\begin{Proof}
\begin{itemize}
\item \textit{non vide :}\\
$\forall i \in \Intf{1}{p}: \vect{0}\in F_i$ donc $\vect{0}\in \cap_{i=1}^p F_i$
\item \textit{stable par $+$ :}\\
Soit $\vect{x}_1,\vect{x}_2 \in \cap_{i=1}^p F_i $ d'où pour tout $i\in \Intf{1}{p}: \vect{x}_1,\vect{x}_2\in F_i$.\\
Ainsi pour tout $i \in \Intf{1}{p}: \vect{x}_1+\vect{x}_2 \in F_i$ donc $\vect{x}_1+\vect{x}_2\in \cap_{i=1}^p F_i$.
\item
  \textit{stable par $.$ :} \\
Soit $\lambda\in \R$ et Soit $\vect{x}\in \cap_{i=1}^p F_i $ d'où $\forall i \in \Intf{1}{p}: \vect{x}\in F_i$.\\
Ainsi pour tout $i \in \Intf{1}{p}: \lambda\vect{x}\in F_i$ donc $\lambda \vect{x}\in \cap_{i=1}^p F_i$.
\end{itemize}
\end{Proof}
\begin{Ex}$F=\overbrace{\{(x,y,z)\in \R^3: z=0\}}^{=F_1}\cap \overbrace{\{(x,y,z)\in \R^3: z=x\}}^{=F_2} $  l'intersection de deux plans vectoriels, $F_1$ et $F_2$ dans $\R ^3$
\begin{center}
\includegraphics[width=6cm]{espace_vectoriel_inter.png}
\end{center}
\end{Ex}

\subsubsection{Somme de sous-espaces vectoriels : $F_1+F2=\{\vec{x}+\vec{y}:\vec{x} \in F_1,\vec{y} \in F_2  \}$ }
\begin{NB}
L'union $\cup_{i=1}^p F_i$ n'est presque jamais un sous espace vectoriel.

\begin{center}
\includegraphics[width=4.5cm]{espace_vectoriel_union.png}
\end{center}
Sur cette figure, les vecteurs $\vect{x},\vect{y}\in F_1\cup F_2$ et on a $\vect{x}+\vect{y}\not\in  F_1 \cup F_2.$ La somme permet de construire le plus petit (au sens de l'inclusion) sous espace vectoriel  de $E$ contenant $F_1$ et $F_2$.
\end{NB}
\begin{DfProp}[Somme]
Soit $E$ un $\K $-espace vectoriel, $F_1$ et $F_2$ deux sous-espaces vectoriels de $E$.\\
On appelle \defi{somme} de $F_1$ et $F_2$ l'ensemble $ F_1+F_2$ des vecteurs de la forme $\vect{x} +\vect{y}$
où $\vect{x}\in F_1$ et $\vect{y}\in F_2$;
autrement dit,
\[  F_1+F_2 = \{\vect{x} +\vect{y} : \vect{x}\in F_1,\vect{y}\in F_2\}. \]
$F_1+F_2$ est un sous espace vectoriel  de $E$.\\
Plus précisément $F_1+F_2$ est le plus petit (au sens de l'inclusion) sous espace vectoriel  de $E$ contenant $F_1$ et $F_2$.
\end{DfProp}
\begin{Proof}
\begin{itemize}
\item \textit{non vide :}\\
$\vect{0}\in F_1,F_2$ d'où $\vect{0}=\underbrace{\vect{0}}_{\in F_1}+\underbrace{\vect{0}}_{\in F_2}\in F_1+F_2.$
\item \textit{stable par $+$ :}\\
Soit $\vect{x_1}+\vect{y_1},\vect{x_2}+\vect{y_2} \in  F_1+F_2.$\\
$\vect{x_1}+\vect{y_1}+\vect{x_2}+\vect{y_2} =\underbrace{\vect{x_1}+\vect{x_2}}_{\in F_1}+\underbrace{\vect{y_1}+\vect{y_2}}_{\in F_2}\in  F_1+F_2.$
\item
  \textit{stable par $.$ :} \\
Soit $\lambda\in \R$ et $\vect{x}+\vect{y}  \in  F_1+F_2.$\\
$\lambda (\vect{x}+\vect{y})=\underbrace{\lambda\vect{x}}_{\in F_1}+\underbrace{\lambda\vect{y}}_{\in F_2} \in  F_1+F_2.$
\end{itemize}
\end{Proof}
\begin{Ex}
Soit $\R \vect{x}_1$ et $\R \vect{x}_2$ deux droite vectorielles distinctes. La somme de ces deux espace vectoriels forme le plan vectoriel $\R \vect{x}_1+\R \vect{x}_2$.
\begin{center}
\includegraphics[width=8cm]{espace_vectoriel_somme.png}
\end{center}
\end{Ex}

\begin{Df}[Somme directe]
Avec les mêmes notations, on dit que la somme $F_1+F_2$ est \defi{directe} si tout vecteur de la somme se décompose \textbf{de façon unique} sous la forme $\vect{x} +\vect{y}$ où $\vect{x}\in F_1$ et $\vect{y}\in F_2$.
On note alors la somme $F_1\oplus F_2$.
\end{Df}
\begin{Prop}[Critère 1]
Avec les mêmes notations, la somme $F_1+F_2$ est directe si et seulement si
$$ \forall \vect{x} \in F_1, \forall \vect{y} \in F_2:\quad 
  \vect{x} +\vect{y} = \vect{0_E} \Rightarrow \vect{x} =  \vect{y} = \vect{0_E}.$$
\end{Prop}
\begin{Proof}$\quad$\\
\begin{itemize}
\item \textit{$(\Longrightarrow)$} :\\
Soit $\vect{x} \in F_1$ et $\vect{y} \in F_2$ tel que $\vect{x} + \vect{y}=\vect{0}$. On a aussi $\underbrace{\vect{0}}_{\in F_1}+\underbrace{\vect{0}}_{\in F_2}=\vect{0}.$ L'unicité de décomposition permet d'identifier  $\vect{x}=\vect{0}$ et $\vect{y}=\vect{0}$.
\item \textit{$(\Longleftarrow)$} :\\
Supposons qu'un $\vect{z} \in F_1+F_2$  se décompose de 2 façons :$\vect{z}= \underbrace{\vect{x}}_{\in F_1} + \underbrace{\vect{y}}_{\in F_2}$ et $\vect{z}= \underbrace{\vect{x'}}_{\in F_1} + \underbrace{\vect{y}}_{\in F_2}$. \\
On soustrait ces deux égalités :
$$\vect{0}= \underbrace{\vect{x} -\vect{x'} }_{\in F_1}+\underbrace{\vect{y} -\vect{y'} }_{\in F_2}.$$
D'après l'hypothèse, on a   $\vect{x} -\vect{x'}=\vect{0}$ et $\vect{y} -\vect{y'}=\vect{0}$, d'où l'unicité de la décomposition avec $\vect{x} =\vect{x'}$ et $\vect{y}=\vect{y'}.$ 
\end{itemize}
\end{Proof}
\begin{Prop}[Critère 2]
Avec les mêmes notations, la somme $F_1+F_2$ est directe si et seulement si $F_1\cap F_2 = \{\vect{0_E}\}$.
\end{Prop}
\begin{Proof}$\quad $\\
\label{Proof:critere2}
\begin{itemize}
\item \textit{$(\Longrightarrow)$ :}
\begin{itemize}[label=*]
\item \textit{$\{\vect{0_E}\}   \subset  F_1\cap F_2$} :
$\vect{0_E}\in F_1,F_2$ donc $\vect{0_E}\in F_1\cap F_2 .$ 
\item \textit{$F_1\cap F_2  \subset \{\vect{0_E}\} $} :
Soit $\vect{x}\in F_1\cap F_2$. 
On a $\vect{0}= \underbrace{\vect{x}}_{\in F_1} + \underbrace{-\vect{x}}_{\in F_2}= \underbrace{\vect{0}}_{\in F_1} + \underbrace{\vect{0}}_{\in F_2}$. Par unicité de la décomposition, on identifie $\vect{x}=\vect{0}.$
\end{itemize}
Du fait de la double inclusion, on a $F_1\cap F_2 = \{\vect{0_E}\}.$\\
\item \textit{$(\Longleftarrow)$ :}\\
Supposons qu'un $\vect{z} \in F_1+F_2$  se décompose de 2 façons :$\vect{z}= \underbrace{\vect{x}}_{\in F_1} + \underbrace{\vect{y}}_{\in F_2}$ et $\vect{z}= \underbrace{\vect{x'}}_{\in F_1} + \underbrace{\vect{y}}_{\in F_2}$. \\
On soustrait ces deux égalités :
$$\underbrace{\vect{x} -\vect{x'} }_{\in F_1}=\underbrace{\vect{y} -\vect{y'} }_{\in F_2}.$$
Comme $F_1\cap F_2 = \{\vect{0_E}\}$, on a $\vect{x} -\vect{x'}=\vect{0}$ et $\vect{y} -\vect{y'} =\vect{0}$, d'où l'unicité de la décomposition avec $\vect{x} =\vect{x'}$ et $\vect{x}=\vect{y'}.$
\end{itemize}

\end{Proof}

\begin{Ex} Géométriquement, l'intersection entre deux plans vectoriels distincts, $F_1$ et $F_2$, est une droite vectoriel, $F_1\cap F_2$, donc la somme n'est pas directe.
\begin{center}
\includegraphics[width=6cm]{espace_vectoriel_inter.png}
\end{center}
Si $F_1=\{(x,y,z)\in\R^3: x+y+z=0\}$ et $F_1=\{(x,y,z)\in\R^3: x-y+z=0\}$. On a :
\begin{align*}
 \vect{x}=(x,y,z)\in F_1 \cap F_2 & \Leftrightarrow \begin{cases}x+y+z=0 \\ x-y+z=0 \end{cases}\\
 & \Leftrightarrow \begin{cases}x+y+z=0 \\ -2y=0 \quad L_2\leftarrow L_2 - L_1\end{cases}\\
 & \Leftrightarrow \begin{cases}x+z=0 \\ y=0 \end{cases}\\
 & \Leftrightarrow  z=\lambda, x=-\lambda , y=0,\quad  \forall t\in \R \\
 & \Leftrightarrow  (x,y,z) = \lambda(-1,0,1),\quad  \forall t\in \R \\
 & \Leftrightarrow  (x,y,z) \in \Vectt( -1,0,1)
 \end{align*}
Finalement  $F_1 \cap F_2 = \R  ( -1,0,1)$. 
\end{Ex}
\begin{Df}[Supplémentaires]
Avec les mêmes notations, si la somme $F_1+F_2$ est directe et égale à $E$,
on dit que $F_1$ et $F_2$ sont \defi{supplémentaires}, et on note
\[ E = F_1\oplus F_2. \]
\end{Df}
\begin{Ex}
Montrons que $\R_n[X]=\R_{n-1}[X]\oplus \Vectt(X^n)$.\\
\begin{itemize}
\item \textit{$\R_n[X]=\R_{n-1}[X]+ \Vectt(X^n) $} :\\
Soit $P =a_0+a_1 X+\dots+a_{n-1} X^{n-1}+a_{n} X^{n}\in \R_n[X].$
On a $$P =\overbrace{a_0+a_1 X+\dots+a_{n-1} X^{n-1}}^{\in \R_{n-1}[X]}+\overbrace{a_{n} X^{n}}^{\in \Vectt(X^n)}.$$
\item \textit{$\R_{n-1}[X]\cap  \Vectt(X^n)=\{\vect{0}_{\R_n[X]}\}$ :}\\
Soit $P \in \R_{n-1}[X]\cap \Vectt(X^n)$.\\
Comme $P \in \R_{n-1}[X]$, on a $deg(P)<n$. Comme  $P \in \Vectt(X^n)$, on a $P=\lambda X^n$. Si $\lambda\neq 0$, on a $deg(P=\lambda X^n)=n$, d'où une contradiction.  Donc $P=0$.  
\end{itemize}
\end{Ex}
\begin{DfProp}[Somme]
Soit $E$ un $\K$-espace vectoriel et $F_1,\dots, F_p$ des sous-espaces vectoriels de $E$.\\
On appelle \defi{somme} de $F_1,\dots, F_p$ l'ensemble $ \sum_{k=1}^p F_k$ des vecteurs de la forme $\vect{x_1} +\vect{x_2}+ \dots + \vect{x_p}$
où $\vect{x_1}\in F_1$, $\vect{x_2}\in F_2$, ..., $\vect{x_p}\in F_p$;
autrement dit,
\[  \sum_{k=1}^p F_k = \{ \vect{x_1} +\vect{x_2}+ \dots + \vect{x_p}: \vect{x_1}\in F_1,\vect{x_2}\in F_2,\dots, \vect{x_p}\in F_p\}. \]
Il s'agit d'un sous espace vectoriel  de $E$;
plus précisément $S$ est le plus petit (au sens de l'inclusion) sous espace vectoriel  de $E$ contenant $F_1,\dots, F_p$.
\end{DfProp}


\begin{Df}[Somme directe]
Avec les mêmes notations, on dit que la somme $\sum_{i=1}^p F_i$ est \defi{directe} si tout vecteur de la somme se décompose \defi{de façon unique} sous la forme $\vect{x_1} +\vect{x_2}+ \dots + \vect{x_p}$ où $\vect{x_1}\in F_1$, $\vect{x_2}\in F_2$, ..., $\vect{x_p}\in F_p$.
On note alors la somme $\oplus_{k=1}^p F_k$.
\end{Df}
\begin{Prop}[Critère 1]
Avec les mêmes notations, la somme $\sum_{i=1}^p F_i$ est directe si et seulement si
$$\vect{x_1}\in F_1, \vect{x_2}\in F_2, ..., \vect{x_p}\in F_p,
 \vect{x_1} +\vect{x_2}+ \dots + \vect{x_p} = \vect{0_E} \implies \vect{x_1} =\dots=\vect{x_p}= \vect{0_E}.$$
\end{Prop}  
\begin{NB}
Le critère 2 ne se généralise pas (simplement) pour $p > 2$.\\
$E = \R ^2$, $\vect{x_1} = (1,0)$, $\vect{x_2} = (0,1)$ et $\vect{x_3} = (1,1)$.
On a $\R \vect{x_1} \cap \R \vect{x_2} = \R \vect{x_1} \cap \R \vect{x_3} = \R \vect{x_2} \cap \R \vect{x_3} = \{(0,0)\}$. Cependant la somme $\R \vect{x_1} + \R \vect{x_2} + \R \vect{x_3}$ n'est pas directe car $(1,1)=1(1,1)$ et $(1,1)=1(1,0)+1(0,1).$ 
\end{NB}



\subsection{Espace vectoriel produit : $(\vec{x_1},\vec{x_2})\in E_1\times E_2$}
\begin{Df}[Produit cartésien]
Soit $(E_1, +_1, ._1)$ et $(E_2, +_2, ._2)$ deux $\K $-espaces vectoriels.\\
On pose \[ E = E_1\times E_2 = \{ (\vect{x_1},\vect{x_2}) : \vect{x_1}\in E_1, \vect{x_2}\in E_2 \}. \]
$E$ est le \defi{produit cartésien} des ensembles $E_1, E_2$.\\
On définit la loi de composition interne $+$ sur $E$ par : 
$$\forall (\vect{x_1},\vect{x_2})\in E, (\vect{y_1},\vect{y_2})\in E,\quad (\vect{x_1},\vect{x_2})+(\vect{y_1},\vect{y_2}) =  (\vect{x_1}+_1\vect{y_1},\vect{x_2}+_2\vect{y_2}). $$
De même, on définit la loi de composition externe $.$ sur $E$ par:
$$\forall \lambda \in \K,\forall (\vect{x_1},\vect{x_2}) \in E,
 \lambda . (\vect{x_1},\vect{x_2}) =(\lambda ._1\vect{x_1},\lambda ._2\vect{x_2}).$$
 \end{Df}
 \begin{Ex}
Pour $p\in \N^*$ et $E$ un $\K $-espace vectoriel, on définit $E^p$ par \[ E^p = \prod_{k=1}^p E. \]
Notez le cas particulier $E = \K $, où $E^p=\K^p$.  
 \end{Ex}
\begin{Prop}
$E$ ainsi défini est un $\K $-espace vectoriel.
\end{Prop}
\begin{Df} 
On définit de manière analogue le $\K $-espace vectoriel $E$,  produit cartésien des ensembles $E_1, \dots, E_n$.  $(E_1, +_1, ._1)$, $(E_2, +_2, ._2)$, ..., $(E_p, +_p, ._p)$ de $\K $-espaces vectoriels $ E = \prod_{k=1}^p E_k = \{ (\vect{x_1},\dots, \vect{x_p}): \vect{x_1}\in E_1, \dots, \vect{x_p}\in E_p \}$.
\end{Df}




% -----------------------------------------------------------------------------
\section{Base: $\forall \vec{x}\in E, \exists !(\lambda_1,\dots \lambda_p),\quad \vec{x} = \lambda_1 \vec{e_1}+\dots +\lambda_p \vec{e_p}$}
\subsection{Définition}
\subsubsection{Famille génératrice : existence}
\begin{Df}[Famille génératrice] Une famille finie  $\mathcal{F}=(\vect{e}_1,\dots,\vect{e_p})$ est \defi{génératrice} de $E$ si tout vecteur de $E$ est combinaison linéaire de $\mathcal{F}$, c'est à dire si $\Vectt(\mathcal{F}) = E$, c'est à dire si 
\[ \forall \vect{x} \in E,\exists \lambda_1,\dots,\lambda_p \in \K,\quad \vect{x} = \lambda_1 \vect{e_1}+ \lambda_2 \vect{e_2}+\dots +\lambda_p \vect{e_p}. \]
\end{Df}
\begin{Ex} La famille  $\{(1,1), (0,1), (1,-1)\}$  est génératrice de $\R^2$. En effet, soit $\vect{x}=(x,y)\in\R^2$, on a :
$$(x,y)=\frac{x+y}{2}(1,1)+ \frac{x-y}{2} (1,-1).$$
En revanche,  la combinaison linéaire n'est pas unique car $(x,y)= x(1,1)+(y-1)(0,1).$
\end{Ex}
\subsubsection{Famille libre : unicité}
\begin{Df}[Famille libre]
Une famille finie  $\mathcal{F}=(\vect{e}_1,\dots,\vect{e_p})$ est \defi{libre} si tout vecteur appartenant à l'espace vectoriel engendré par la famille s'exprime de manière unique comme combinaison linéaire de la famille, c'est à dire si 
\[ \forall \vect{x} \in \Vectt((\vect{e}_1,\dots,\vect{e_p}),\exists ! \lambda_1,\dots,\lambda_n \in \K,\quad \vect{x} = \lambda_1 \vect{e_1}+ \lambda_2 \vect{e_2}+\dots +\lambda_p \vect{e_p}. \]
Autrement dit aucun des vecteurs de la famille n'est combinaison linéaire des autres.
\end{Df}
\begin{Prop}[Critère]
Une famille finie  $\mathcal{F}=(\vect{e}_1,\dots,\vect{e_p})$ est libre si et seulement si la seule combinaison linéaire de $\mathcal{F}$ nulle est triviale, c'est à dire
$$ \forall \lambda_1,\dots,\lambda_p   \in \K,\quad  \lambda _1 \vect{e_1}+\dots+\lambda _n \vect{e_n} = \vect{0_E} \Rightarrow \lambda _1=\lambda _2=\dots=\lambda_p= 0_\K  .$$
\end{Prop}
\begin{Proof}
La démonstration est similaire au critère 2 de la somme directe (voir démonstration~\ref{Proof:critere2}).
\end{Proof}
\begin{Ex}
Dans l'exemple précédent, on a démontré qu'un vecteur pouvait s'exprimer à l'aide de deux combinaisons linéaires distinctes. Avec ce dernier critère, la démonstration serait :\\
Soit $\lambda,\beta,\alpha \in \R$ tel que $$\lambda (1,1) + \beta  (0,1) + \alpha (1,-1)    =(0,0).$$
On a : 
$$ \begin{cases}\lambda +\alpha &=0\\\lambda+\beta-\alpha&=0\end{cases}\Rightarrow \begin{cases}\lambda &=1\\\ \alpha&=-1\\ \beta&=-2 \end{cases}.$$
On vérifie que $(1,1)-2(0,1)- (1,-1) =(0,0)$.
\end{Ex}
\subsubsection{Base : existence et unicité}
\begin{Df}
On dit que la famille $\mathcal{F}=(\vect{e}_1,\dots,\vect{e_p})$ est une \defi{base} de $E$ si elle est libre et génératrice.\\
De façon équivalente, la famille $(\vect{e}_1,\dots,\vect{e_p})$ est une base de $E$ si
\[ \forall \vect{x}\in E, \exists !  \lambda_1,\dots,\lambda_p   \in \K ,\quad  \vect{x} = \lambda_1 \vect{e_1}+ \lambda_2 \vect{e_2}+\dots +\lambda_p \vect{e_p}. \]
\end{Df}
\begin{Ex}
L'espace vectoriel des polynôme de degré inférieur ou égal à $n$, $\K _n[X]$,  admet une base $(1,X,X^2,\dots,X^n)$, appelée base canonique.
\end{Ex}
\begin{Ex}
L'espace vectoriel des matrices carrés de taille $2$, $\Mn{2}{\R}$,  admet une base $(\begin{pmatrix}1,0\\0,0\end{pmatrix},\begin{pmatrix}0,1\\0,0\end{pmatrix},\begin{pmatrix}0,0\\1,0\end{pmatrix},\begin{pmatrix}0,0\\0,1\end{pmatrix} )$, appelée base canonique.
\end{Ex} 
 
\begin{NB} On n'a pas unicité de la base. Par exemple pour $\K _n[X]$, avec les $x_i$ $n+1$ scalaires distincts, les polynômes de Lagrange 
$$ l_{i}(X)=\prod _{j=0,j\neq i}^{n}{\frac {X-x_{j}}{x_{i}-x_{j}}} $$
$$l_{i}(X)={\frac {X-x_{0}}{x_{i}-x_{0}}}\cdots {\frac {X-x_{i-1}}{x_{i}-x_{i-1}}}~{\frac {X-x_{i+1}}{x_{i}-x_{i+1}}}\cdots {\frac {X-x_{n}}{x_{i}-x_{n}}}$$   forment une base de $\K _n[X]$.
\end{NB}

\subsection{Existence d'une base}
\begin{Df}[Dimension finie]
Soit $E$ un $\K $-espace vectoriel.\\
On dit que $E$ est \defi{de dimension finie} s'il existe une famille finie génératrice de $E$,
et \defi{de dimension infinie} sinon.
\end{Df}
\begin{Ex}
L'espace vectoriel des polynôme est de dimension infinie.\\
En revanche, l'espace vectoriel des polynôme de degré inférieur ou égal à $n$ est finie.
\end{Ex}
\begin{Ex}
L'espace vectoriel des fonctions continues réels est  de dimension infinie.
\end{Ex}

\begin{Th}[Théorème de la base incomplète]
Soit $E$ un espace vectoriel de dimension finie et $\mathcal{L}$ une famille libre de $E$.\\  
Alors il existe une base $\mathcal{B}$ de $E$ telle que $\mathcal{L}\subset \mathcal{B}$.
\end{Th}
\begin{Proof}
La démonstration  repose sur l'algorithme suivant :\\
Soit la partie libre initiale $\mathcal{L}$.\\
Comme $E$ est un espace vectoriel de dimension finie, il existe une famille finie, $\mathcal{G}$, génératrice de $E$.\\
Tant que $\mathcal{L}$ n'est pas génératrice de $E$ :
\begin{enumerate}
\item Puisque $\mathcal{G}$ engendre $E$ et que $\mathcal{L}$ n'est pas génératrice de $E$, il existe un vecteur $\vect{g}$ de $\mathcal{G}$ qui n'est pas une combinaison linéaire d'éléments de $\mathcal{L}$.
\item On remplace $\mathcal{L}$ par $\mathcal{L}\cup \{\vect{g} \}$, qui est encore libre car le nouveau vecteur n'est pas une combinaison linéaire des précédents.
\end{enumerate}
La boucle se termine en un nombre fini d'étapes puisqu'on ajoute à chaque étape un élément de $\mathcal{G}$ différent des précédents et que $\mathcal{G}$ est fini. $\mathcal{L}$ est alors une partie génératrice, donc une base de $E$.
\end{Proof}
\begin{Th}[Théorème de la base extraite]
Soit $E$ un espace vectoriel de dimension finie et $\mathcal{G}$ une famille génératrice de $E$. \\ 
Alors il existe une base $\mathcal{B}$ de $E$ telle que $\mathcal{B}\subset \mathcal{G}.$
\end{Th}
\begin{Proof}
La démonstration est identique à la précédente exceptée que $\mathcal{L}=\emptyset$.
\end{Proof}

\subsection{Unicité du cardinal de la base}
\begin{Prop}
Si $E$ est un espace vectoriel de dimension finie admettant une famille génératrice de $n$ vecteurs, alors toute famille de $n+1$ vecteurs est liée.
\end{Prop}
\begin{Proof}
Démontrons cette proposition par récurrence.
\begin{itemize}
\item \textit{Initialisation} :\\
Soit $(\vect{g}_1)$ une famille génératrice de $E$.\\
Soit $(\vect{v}_1,\vect{v}_2)$ une famille de $E$. Il existe $\lambda_1$ et $\lambda_2$ dans $\R$ tel que $\vect{v}_1=\lambda_1 \vect{g}_1$ et $\vect{v}_2=\lambda_2 \vect{g}_1$.\\
Si  $\lambda_1=\lambda_2=0$ alors la famille $(\vect{v}_1=\vect{0},\vect{v}_2=\vect{0})$ est liée.\\
Si $\lambda_1\neq 0$, alors $\vect{v}_1=\frac{\lambda_2}{\lambda_1}\vect{v}_2$. Les vecteurs sont colinéaires donc liées.\\
Idem si $\lambda_2\neq 0$.\\
\item \textit{Hérédité} :\\
Soit $(\vect{g_1},\dots,\vect{g_n})$ une famille génératrice de $E$.\\
Soit $(\vect{v}_1, \vect{v}_2,\dots \vect{v}_{n+1})$ une famille de $n+1$ vecteurs de $E$.\\
Pour tout $i\in \Intf{1}{n+1}$, il existe $\lambda_{i,1},\lambda_{i,2},\dots,\lambda_{i,n}\in\K$ tel que $$\vect{v}_i=  \lambda_{i,1}\vect{g}_1 + \lambda_{i,2}\vect{g_2}+\dots+\lambda_{i,n}.\vect{g_n}$$
Quitte à réorganiser les deux familles, on peut supposer que $\lambda_{n+1,n}\neq 0$. \\
Pour tout  $i\in \Intf{1}{n}$, on a 
$$\vect{v}_i-\frac{\lambda_{i,n}}{\lambda_{n+1,n}}\vect{v}_{n+1}\in \Vectt(\vect{g_1},\dots,\vect{g}_{n-1}).$$
On applique l'hypothèse de récurrence à l'espace vectoriel générée par la famille $(\vect{g_1},\dots,\vect{g}_{n-1})$. Donc la famille $\left(\vect{v}_1-\frac{\lambda_{1,n}}{\lambda_{n+1,n}}\vect{v}_{n+1},\dots, \vect{v}_n-\frac{\lambda_{n,n}}{\lambda_{n+1,n}}\vect{v}_{n+1}\right)$ est liée. Il existe  $\beta_{1},\beta_{2},\dots,\beta{n}\in\K$ non tous nuls tel que :
$$\beta_1 (\vect{v}_1-\frac{\lambda_{1,n}}{\lambda_{n+1,n}}\vect{v}_{n+1})+\dots+\beta_n (\vect{v}_n-\frac{\lambda_{n,n}}{\lambda_{n+1,n}}\vect{v}_{n+1})=\vect{0}.$$
d'où 
$$\beta_1\vect{v}_1+\dots +\beta_n\vect{v}_n - (\beta_1\frac{\lambda_{1,n}}{\lambda_{n+1,n}}+\dots +\beta_n\frac{\lambda_{n,n}}{\lambda_{n+1,n}})\vect{v}_{n+1}=\vect{0}.$$
La famille est donc liée. 
\end{itemize}
\end{Proof}
\begin{Prop}
Si $E$ est un espace vectoriel de dimension finie admettant une famille génératrice de $n$ vecteurs, alors toute famille ayant strictement plus de $n$ vecteurs est liée.
\end{Prop}
\begin{Proof}
Si la famille a strictement plus de $n$ vecteurs, on peut en enlever pour constituer une famille de $n+1$ vecteurs qui est donc liée d'après la proposition précédente. A fortiori, la famille initiale est liée. 
\end{Proof}

\begin{Prop}[Unicité du cardinal d'une base]
Soit $E$ un espace vectoriel de dimension finie et $(\vect{e}_1,\dots,\vect{e_p})$ et $(\vect{f}_1,\dots,\vect{f_q})$ deux bases de $E$.\\
Alors $p=q$.
\end{Prop}
\begin{Proof}
$(\vect{e}_1,\dots,\vect{e_p})$ est une famille génératrice de $E$. Comme $(\vect{f}_1,\dots,\vect{f_q})$ est libre d'après la proposition précédente,  $q\leq p$.
Par symétrie, on a aussi $p\leq q$. Finalement $p=q$.
\end{Proof}
Cette proposition nous permet cette définition.
\begin{DfProp}[Dimension]
La \defi{dimension} d'un espace vectoriel de dimension finie est égale au cardinal d'une base quelconque de $E$.
\end{DfProp}

\begin{Prop}[Critère]
Soit $E$ un espace vectoriel de dimension $n$.\\
Si $(\vect{e}_1,\dots,\vect{e_n})$ est une famille libre, alors $(\vect{e}_1,\dots,\vect{e_n})$ est une base de $E$.\\
Si $(\vect{e}_1,\dots,\vect{e_n})$ est une famille génératrice, alors $(\vect{e}_1,\dots,\vect{e_n})$ est une base de $E$.
\end{Prop}
\begin{Ex} Pour tout polynôme $P$ appartenant à $\K _{n}[X]$, la combinaison linéaire des polynômes de Lagrange  $\sum _{j=0}^{n}P(x_{j})l_{j}(X)$ avec $x_{0},\ldots ,x_{n}$ $n + 1$ scalaires distincts  est égale au polynôme $P$ aux points $x_{0},\ldots ,x_{n}$, donc égal à $P$. Les polynômes de Lagrange forment une famille génératrice de $n+1$ vecteurs. Comme $\dim(\K _{n}[X])=n+1$, ils forment une base de $\K _{n}[X]$. 
\end{Ex}

\begin{Prop}
Soit $E$ un espace vectoriel de dimension finie et $F$ un sous espace vectoriel de $E$.\\
Alors $F$ est également de dimension finie et $\dim F \leq \dim E$, avec égalité si et seulement si $F = E$.
\end{Prop}

\subsection{Base adaptée}

\begin{Df}[Base adaptée]
Soit $E$ un $\K $-espace vectoriel de dimension  $n$ et $F$ un sous espace vectoriel de $E$.\\
La base $(\vect{e}_1,\dots,\vect{e_n})$ est dite \defi{adaptée} à $F$
si et seulement s'il existe $p\in \Intf{1}{n}$ tel que $(\vect{e}_1,\dots,\vect{e_p})$ soit une base de $F$.
\end{Df}
\begin{Ex} La base $((1,-1,0),(0,1,-1),(0,0,1))$ est adaptée à $F=\{(x,y,z)\in\R ^3: x+y+z=0\}$ dans l'espace vectoriel $\R ^3$ car $((1,-1,0),(0,1,-1))$ est une base de $F$. 
\end{Ex}
\begin{Prop}[Existence d'une base adaptée]
La base ainsi définie existe.
\end{Prop}
\begin{Proof}
Comme $F$ est un espace vectoriel de dimension finie, il existe une base $(\vect{e}_1,\dots,\vect{e_p})$ de $F$. Cette famille est libre dans $E$. On la complète en une base de $E$ d'après le théorème de la base incomplète.  
\end{Proof}
\begin{Df}
Soit $E$ un $\K $-espace vectoriel de dimension finie, $F_1,\dots, F_p$ des sous-espaces vectoriels supplémentaires de $E$ et $B$ une base de $E$.\\
La base $\mathcal{B}$ est dite \defi{adaptée} à la décomposition $E =\oplus_{k=1}^p F_k$ si et seulement si $\mathcal{B}$ peut s'écrire comme la concaténation de $\mathcal{B}_1,\dots,\mathcal{B}_p$ où $\mathcal{B}_k$ est une base de $F_k$ pour tout $k\in \Intf{1}{p}$.
\end{Df}
\begin{Prop}
 La base ainsi définie existe.
\end{Prop}
\begin{Prop}
\label{prop:base}
Soit $E$ un $\K $-espace vectoriel de dimension finie et $\mathcal{B}$ une base de $E$.\\
On suppose que $\mathcal{B}$ s'écrit comme la concaténation de $\mathcal{B}_1,\dots \mathcal{B}_p$.\\
Pour $k\in \Intf{1}{p}$, notons $F_k$ le sous espace vectoriel engendré par $\mathcal{B}_k$.\\
Alors les sous-espaces vectoriels $F_1,\dots, F_p$ sont supplémentaires.
\end{Prop}

\section{Théorèmes en dimension finie}
\begin{Prop}[Existence d'un supplémentaire]
Dans un espace vectoriel de dimension finie, tout sous espace vectoriel admet un supplémentaire.\\
Autrement dit, soit $E$ est un espace vectoriel de dimension finie et $F$ un sous espace vectoriel de $E$.\\
Alors il existe un sous espace vectoriel $G$ de $E$ tel que $E = F \oplus G$.
\end{Prop}
\begin{Proof}
Soit $\mathcal{B}_1$ une base de $F$ que l'on complète avec $\mathcal{B}_2$ pour former une base de $E$.\\
D'après la proposition \ref{prop:base}, si on pose $G$ l'espace vectoriel engendrée par  $\mathcal{B}_2$, alors $E = F \oplus G$.  
\end{Proof}
\begin{Prop}
Soit $E_1,\dots E_p$ des $\K $-espaces vectoriels.\\
L'espace vectoriel produit $\prod_{k=1}^p E_k$ est de dimension finie si et seulement si $\forall k\in \Intf{1}{p}$, $E_k$ est de dimension finie.\\
De plus, dans ce cas, \[ \dim( \prod_{k=1}^p E_k ) = \sum_{k=1}^p \dim(E_k). \]
\end{Prop}
\begin{Proof}
On suppose $p=2$.\\
Soit $(\vect{e_1},\dots,\vect{e_n})$ une base de $E_1$ et $(\vect{f_1},\dots,\vect{f_q})$ une base de $E_2$.\\
Alors $( (\vect{e_1},\vect{0}_F),\dots,(\vect{e_n},\vect{0}_F),(\vect{0}_E,\vect{f_1}),\dots,(\vect{0}_E,\vect{f_q}))$ est une base de $E_1\times E_2.$
\begin{itemize}
\item \textit{Génératrice} :\\
Soit $(\vect{x},\vect{y})\in E_1\times E_2$. \\
Comme $\vect{x}\in E_1$ et $(\vect{e_1},\dots,\vect{e_n})$ est une famille génératrice de $E_1$, il existe $\lambda_1,\dots,\lambda_n\in \K$ tel que $\vect{x}=\lambda_1\vect{e_1}+\dots+ \lambda_n\vect{e_n}$.\\
Comme $\vect{y}\in E_2$ et $(\vect{f_1},\dots,\vect{f_q})$ est une famille génératrice de $E_2$, il existe $\beta_1,\dots,\beta_q\in \K$ tel que $\vect{y}=\beta_1\vect{f_1}+\dots+ \beta_q\vect{f_q}$.\\
D'où $(\vect{x},\vect{y})=\lambda_1(\vect{e_1},\vect{0}_F)+\dots+\lambda_n(\vect{e_n},\vect{0}_F)+ \beta_1(\vect{0}_E,\vect{f_1})+\dots+\beta_q(\vect{0}_E,\vect{f_q}).$
\item \textit{Libre} :\\
Soit  $\lambda_1,\dots,\lambda_n,\beta_1,\dots,\beta_q\in \K$ tel que $$\lambda_1(\vect{e_1},\vect{0}_F)+\dots+\lambda_n(\vect{e_n},\vect{0}_F)+ \beta_1(\vect{0}_E,\vect{f_1})+\dots+\beta_q(\vect{0}_E,\vect{f_q})=(\vect{0}_E,\vect{0}_F).$$
D'où:
$$(\lambda_1\vect{e_1}+\dots+ \lambda_n\vect{e_n},\beta_1\vect{f_1}+\dots+ \beta_q\vect{f_q} )=(\vect{0}_E,\vect{0}_F).$$
Par identification, on obtient $\lambda_1\vect{e_1}+\dots+ \lambda_n\vect{e_n}=\vect{0}_E$ et $\beta_1\vect{f_1}+\dots+ \beta_q\vect{f_q}=\vect{0}_F$. Comme $(\vect{e_1},\dots,\vect{e_n})$ et $(\vect{f_1},\dots,\vect{f_q})$ sont des familles libres de $E_1$ et  de $E_2$ respectivement, $\lambda_1=\dots=\lambda_n=\beta_1=\dots=\beta_q=0$. 
\end{itemize}
\end{Proof}

\begin{Cor}
Pour $p\in \N^*$ et $E$ un $\K $-espace vectoriel.\\
L'espace vectoriel $E^p$ est de dimension finie si et seulement si $E$ l'est;
dans ce cas, on a $\dim(E^p) = p.\dim(E)$.
\end{Cor}
\begin{Prop}[Formule de Grassmann]
Soit E un $\K $-espace vectoriel dimension finie et $F_1$, $F_2$ deux sous espace vectoriel de $E$. On a :
$$\dim (F_1 + F_2) = \dim F_1 + \dim F_2 - \dim(F_1 \cap F_1).$$
\end{Prop}
\begin{Proof}
Une idée est de remarquer l'analogie avec la formule ensembliste  :
$$\text{card}(A)+\text{card}(B)=\text{card}(A\cup B)+\text{card}(A\cap B).$$
Soit $(\vect{e_1},\dots,\vect{e_p})$ une base de $F_1\cap F_2$. On la complète en une base 
$(\vect{e_1},\dots,\vect{e_p},\vect{f_{p+1}},\dots,\vect{f_{p+k}})$ de $F_1$ et en une base $(\vect{e_1},\dots,\vect{e_p},\vect{g_{p+1}},\dots,\vect{g_{p+m}})$ de $F_2$. $(\vect{e_1},\dots,\vect{e_p},\vect{f_{p+1}},\dots,\vect{f_{p+k}},\vect{g_{p+1}},\dots,\vect{g_{p+m}})$ est une base   $F_1+F_2$.\\
Comme le cardinal d'une base est égale à la dimension de l'espace vectoriel, on obtient bien l'égalité souhaitée.
\end{Proof}
\begin{Prop}
Soit $E$ un $\K $-espace vectoriel et $F_1,\dots F_p$ des sous-espaces vectoriels de dimension finie de $E$.
Alors la somme $\sum_{k=1}^p F_k$ est également de dimension finie, et
\[ \dim\left(\sum_{k=1}^p F_k \right)  \leq \sum_{k=1}^p \dim(F_k). \]
De plus, il y a égalité si et seulement si la somme $\sum_{k=1}^p F_k$ est directe.
\end{Prop}
\begin{Prop}
Soit $E$ un $\K $-espace vectoriels de dimensions finies et $F_1, \dots, F_p$ des sous espaces vectoriels de $E$.\\
On suppose que \[ \sum_{k=1}^p \dim F_k = \dim E. \]
Les conditions suivantes sont alors équivalentes:
\begin{enumerate}
\item
 les sous espaces vectoriels $F_1, \dots, F_p$ sont supplémentaires,
\item
  les sous espaces vectoriels $F_1, \dots, F_p$ sont en somme directe,
\item  $\sum_{k=1}^p F_k = E$.
\end{enumerate}
\end{Prop}
%TODO ECRIRE CETTE PARTIE
\section{Retour aux matrices}
\begin{Prop}[Structure de $\K $-espace vectoriel]
$\MnpK$ possède une structure de $\K $-espace vectoriel. 
\end{Prop}
\begin{Proof}
Tous les axiomes se vérifient aisément.  
\end{Proof}
\begin{DfProp}[Base canonique]La \defi{base canonique} est $(E_{ij})_{1\leqslant i\leqslant n, 1\leqslant j\leqslant p}$ où la matrice  $E_{i,j}$ est celle dont tous les coefficients sont nuls sauf celui d'indice $(i,j)$ , qui vaut 1.\\
 Les coordonnées dans la base canonique d'une matrice $A$ sont ses coefficients :
 $$ \begin{pmatrix}
a_{11} & \cdots & a_{1p}\\
 \vdots &  & \vdots\\
a_{n1} & \cdots & a_{np}
\end{pmatrix} =a_{11}\begin{pmatrix}
1 & \cdots & 0\\
 \vdots &  & \vdots\\
0 & \cdots & 0
\end{pmatrix}+\dots+a_{1p}\begin{pmatrix}
0 & \cdots & 1\\
 \vdots &  & \vdots\\
0 & \cdots & 0
\end{pmatrix}+ \dots+a_{n1}\begin{pmatrix}
0 & \cdots & 0\\
 \vdots &  & \vdots\\
1 & \cdots & 0
\end{pmatrix}+\dots+a_{np} \begin{pmatrix}
0 & \cdots & 0\\
 \vdots &  & \vdots\\
0 & \cdots & 1
\end{pmatrix},$$
 $$ \begin{pmatrix}
a_{11} & \cdots & a_{1p}\\
 \vdots &  & \vdots\\
a_{n1} & \cdots & a_{np}
\end{pmatrix} =  \sum _{1\leqslant i\leqslant n\atop 1\leqslant j\leqslant p}  a_{ij} E_{ij}.$$
On a $\dim( \MnpK)=np$.
\end{DfProp}
\begin{Proof}
Du fait de l'égalité, $ A = \sum _{1\leqslant i\leqslant n\atop 1\leqslant j\leqslant p}  a_{i,j} E_{i,j}$,  $(E_{i,j})_{1\leqslant i\leqslant n, 1\leqslant j\leqslant p}$ est une famille génératrice de $\MnpK$.\\
Soit  $(\lambda_{ij})_{1\leqslant i\leqslant n, 1\leqslant j\leqslant p}$ une famille de scalaires tel que
$$\sum _{1\leqslant i\leqslant n\atop 1\leqslant j\leqslant p}  \lambda_{ij} E_{i,j}=0_{\MnpK}.$$
D'où :
 $$\begin{pmatrix}
\lambda_{11} &  \cdots & \lambda_{1p}\\
\vdots & \ \ddots & \vdots\\
\lambda_{n1} &  \cdots & a_{np}\\
\end{pmatrix}= \begin{pmatrix}
0 &  \cdots &0\\
\vdots & \ \ddots & \vdots\\
0 &  \cdots & 0\\
\end{pmatrix}$$
Par identification, $\lambda_{ij}=0$ pour tout $i\in\Intf{1}{n}$ et  $j\in\Intf{1}{p}$, donc la famille est libre.\\
La famille est donc une base. Comme la cardinal de la base $\card((E_{i,j})_{1\leqslant i\leqslant n, 1\leqslant j\leqslant p})$ est $np$, on a bien $\dim( \MnpK)=np$.
\end{Proof}
\begin{Ex}$ \begin{pmatrix}
0 &1  \\
4 & 3 \\
\end{pmatrix} =
0\cdot
\begin{pmatrix}
1 &0  \\
0 & 0  \\
\end{pmatrix}
+
1\cdot
\begin{pmatrix}
0 &1  \\
0 & 0 \\
\end{pmatrix}
+
4\cdot
\begin{pmatrix}
0 &0  \\
1 & 0  \\
\end{pmatrix}
+
3\cdot
\begin{pmatrix}
0 &0  \\
0 & 1  \\
\end{pmatrix}
$
\end{Ex}

\end{document}
