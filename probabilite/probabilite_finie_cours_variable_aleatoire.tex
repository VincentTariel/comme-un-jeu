\section{Variable aléatoire}
\begin{Ex}[Jeu]Pour attirer les clients, un casino propose un nouveau jeu : le croupier lance simultanément 2 dés et calcule leur somme,
\begin{itemize} 
\item si la somme est égale à 2 ou 12, le joueur gagne 2 euros,
\item si la somme est égale à 7, le casino gagne 1 euro,
\item dans les autres cas, c'est nul (le joueur gagne 0 euro).  
\end{itemize}
A votre avis, ce jeu est-il favorable au joueur ou au casino ? A chaque partie quelle est le gain moyen du joueur ?


Dans ce jeu, on fait intervenir le hasard en observant la somme des points marqués par deux dés. Considérons le jet d'un dé bleu et d'un dé
rouge et notons $S$ la somme des points obtenus. On modélise cette expérience
en prenant l'équiprobabilité sur l'univers  
$$\Omega=\overbrace{\{1,2,3,4,5,6\}}^{\text{issues du dé bleu}}\times \overbrace{\{1,2,3,4,5,6\}}^{\text{issues du dé rouge}}.$$
Une issue, $\omega$, est un couple $(b, r)$ où b désigne le chiffre du
dé bleu et r celui du rouge. La somme $S$ est l'application :
$$\Fonction{S}{\Omega}{\{2,3,\dots,12\} }{(b, r)}{b+r}$$ 
Cette application est représentée par ce tableau  : 
\begin{center}
\begin{tabular}{c||c|c|c|c|c|c}
 \backslashbox{$b$}{$r$} & 1 & 2&3&4&5&6 \\\hline\hline
1 & 2 & 3 & 4&5&6&7\\
2 & 3 & 4 & 5&6&7&8\\
3 & 4 & 5 & 6&7&8&9\\
2 & 5 & 6 & 7&8&9&10\\
1 & 6 & 7 & 8&9&10&11\\
2 & 7 & 8 & 9&10&11&12\\
\end{tabular}
\end{center}
On dit que S est une variable aléatoire sur $\{2,3,\dots,12\}$.\\
En fait, l'observation qui nous intéresse dans cette expérience, ce n'est pas $\omega$,  mais seulement $S(\omega)$. On aimerait connaître la probabilité que
la somme des points prenne une valeur donnée, soit $P(S = k)$ pour $k$ entier
fixé entre 2 et 12. \\
La méthode est de déterminer l'ensemble des issues donnant $(S=k)$ en lisant le tableau ci-dessous puis de calculer la probabilité de cette ensemble. Par exemple, on a $(S=3)=\{(1,2),(2,1)\}$, puis $P(S=3)=P(\{(1,2),(2,1)\})\overbrace{=}^{\text{équiprobabilité}}\frac{\card(\{(1,2),(2,1)\}) }{\card(\Omega)}=\frac{2}{36}$.\\
On obtient ainsi :
\begin{center}
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|c|}
\hline
$k$ & 2 & 3& 4& 5& 6& 7& 8& 9& 10& 11& 12 \\\hline
$P(S=k)$ & $\frac{1}{36}$ & $\frac{2}{36}$& $\frac{3}{36}$& $\frac{4}{36}$& $\frac{5}{36}$& $\frac{6}{36}$& $\frac{5}{36}$& $\frac{4}{36}$& $\frac{3}{36}$& $\frac{2}{36}$& $\frac{1}{36}$\\\hline
\end{tabular}
\end{center}
Cela revient à considérer un nouvel univers :
$$\Omega'=\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}$$
et à munir cet ensemble de la probabilité $P_S$ définie par le tableau des $P(S =
k)$. Cette nouvelle probabilité s'appelle loi de la variable aléatoire S.
\end{Ex}

\subsection{Définition}

\begin{Df}[Variable aléatoire]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini.\\
Une \defi{variable aléatoire réelle} est une application : $$\Fonction{X}{\Omega}{\R}{\omega}{X(\omega)}.$$
On note $X(\Omega)=\{X(\omega):\omega \in \Omega \}$ l'ensemble des images de la variable aléatoire.\\
Comme $\Omega$ est fini, $X(\Omega)$ est aussi finie. On s'autorise désormais à écrire l'ensemble des images sous la forme $X (\Omega) = \{x_1,x_2,\dots,x_n\}$.
\end{Df}
\begin{NB}
Malgré son nom, une variable aléatoire n'est pas une variable (c'est une fonction) et elle n'est pas aléatoire.
\end{NB}
\begin{Df}[Événements associés à une variable aléatoire]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini et $X$ une variable aléatoire réelle sur cette espace.\\
Pour tout $A\subset \R$, on définit l'événement $\{ X \in A \}$ comme étant
\[ X^{-1}(A) = \{\omega\in\Omega :   X(\omega )\in A\}. \]
Dans le cadre de ce chapitre, nous aurons recours aux notations suivantes, pour $x \in \R$ et $A \subset \R$ :
\begin{align*}
(X\in A)=&X^{-1}(A)=\{\omega  \in \Omega | X (\omega) \in A\}\\
(X = x ) =& X^{-1}(\{x\}) = \{\omega \in \Omega | X (\omega) = x \}\\
(X \leq x ) =& X^{-1}(]-\infty,x]) = \{\omega \in \Omega | X (\omega) \leq x \}\\
(X < x ) =& X^{-1}(]-\infty,x[) = \{\omega \in \Omega | X (\omega) < x \}\\
(X \geq x ) =& X^{-1}([x,+\infty[) = \{\omega \in \Omega | X (\omega) \geq x \}\\
(X > x ) =& X^{-1}(]x,+\infty[) = \{\omega \in \Omega | X (\omega) > x \}\\
\end{align*}
\end{Df}


\begin{Ex}[Jeu]
Par exemple, l'ensemble des issues donnant une somme à 7 est :
$$\{S=7\}= S^{-1}(\{7\})=\{(1,6),(2,5),(3,4),(4,3),(5,2),(6,1)\}.$$
et l'ensemble des issues donnant une somme à 2 ou 12 est :
$$\{S\in \{2,12\}\}= S^{-1}(\{2,12\})=\{(1,1),(6,6)\}.$$
\end{Ex}
\begin{Prop}
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini et $X$ une variable aléatoire réelle sur cette espace.\\
L'ensemble $(X=x_i)_{1\leq i\leq n}$ forme un système complet d'événements de $\Omega$.
\begin{center}
\begin{tikzpicture}[scale=0.75]
\draw[fill=red!20] (-4,1) rectangle (-2,4) node[pos=.5] {$\{X=x_1\}$} ;
\draw[fill=blue!20] (-4,-1) rectangle (-1,1)node[pos=.5] {$\{X=x_2\}$};
\draw[fill=green!20] (-2,2) rectangle (4,4) node[pos=.5] {$\{X=x_3\}$} ;
\draw (1,0) node  {$\dots$} ;
\draw \E;
\end{tikzpicture} 
\end{center}
\end{Prop}
\begin{proof}
\begin{itemize}
\item \textit{disjoints :} Soit $i\neq j$. $\{i\}$ et $\{j\}$ sont deux ensembles disjoints. Donc $X^{-1}(\{i\})$ et $X^{-1}(\{j\})$ sont aussi disjoints.   
\item $\cup_{i=1}^n (X=x_i)=\cup_{i=1}^n X^{-1}(\{x_i\})\overbrace{=}^{\text{Formule de Hausdorff}} X^{-1}(\cup_{i=1}^n\{x_i\})=X^{-1}(X(\Omega))=\Omega.$ 
\end{itemize}
\end{proof}

\subsection{Loi de probabilité}
\begin{DfProp}[Loi d'une variable aléatoire]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini et $X$ une variable aléatoire réelle sur cette espace.\\
L'application
\[ \Fonction{P_X}{\mathcal{P}(X(\Omega))}{[0,1]}{A}{P(X^{-1}(A))} \]
est une probabilité sur $X(\Omega)$, appelée \defi{loi de la variable $X$}.
\end{DfProp}
\begin{proof}
\begin{itemize}
\item $P_X(X(\Omega))=P(X^{-1}(X(\Omega)))=P(\Omega)=1$
\item Soit $A$ et $B$ deux événements incompatibles de $X(\Omega)$. Ainsi $X^{-1}(A)$ et $X^{-1}(B)$ sont deux événements incompatibles de $\Omega$. On a
 $$P_X(A\cup B)=P(X^{-1}(A\cup B))=P(X^{-1}(A)\cup X^{-1}(B))$$
Comme  $X^{-1}(A)$ et  $X^{-1}(B)$ incompatibles, on a :
 $$P_X(A\cup B)=P(X^{-1}(A))+ P(X^{-1}(B))=P_X(A)+P_X(B).$$
\end{itemize}
\end{proof}
\begin{Prop}[Déterminer une loi]
Déterminer \defi{la loi de probabilité $P_X$} de la variable aléatoire $X$, c'est donner
\begin{enumerate}
\item l'ensemble $X(\Omega)=\{x_1,\dots,x_n\}$ des valeurs prises par $X$,
\item pour chaque $x_i$ de $X(\Omega)$, la probabilité $p_i=P(X=x_i)$. 
\end{enumerate} : 
\end{Prop}
\begin{proof}
Soit $A \in \mathcal{P}(X(\Omega))$. Il existe $I\subset\Intf{1}{n}$ tel que $A=\{x_i:i\in I\}$.\\
On a
$$P(X\in A)=P(\bigcup_{i\in I} (X=x_i))\overbrace{=}^{ (\{X= x_i\})_{i\in I}\text{ disjoints}}\sum_{i\in I}P(X=x_i).$$
\end{proof}
\begin{NB}
\begin{itemize}
\item $\forall i\in \Intf{1}{n}:\quad p_i=\sum_{\omega\in\Omega \text{ tel que }X(\omega)=x_i}P(\{\omega\})$,
\item Comme les événements $X=x_1,X=x_2,\dots,X=x_n$ forme un système complet d'événements de $\Omega$, on a :
$$\sum_{x_i\in X(\Omega)}P(X=x_i)=\sum_{i=1}^n p_i=1.$$
\end{itemize} 
\end{NB}

\begin{Ex}[Jeu]
La variable aléatoire somme $\Fonction{S}{\Omega}{\{2,3,\dots,12\} }{(b, r)}{b+r}$ est déterminée par ce tableau  :
\begin{center}
\begin{tabular}{c||c|c|c|c|c|c}
 \backslashbox{$b$}{$r$} & 1 & 2&3&4&5&6 \\\hline\hline
1 & 2 & 3 & 4&5&6&7\\
2 & 3 & 4 & 5&6&7&8\\
3 & 4 & 5 & 6&7&8&9\\
2 & 5 & 6 & 7&8&9&10\\
1 & 6 & 7 & 8&9&10&11\\
2 & 7 & 8 & 9&10&11&12\\
\end{tabular}
\end{center}
Du fait de l'équiprobabilité, on détermine la loi de probabilité $S$ en calculant le nombre de cases. Par exemple,
$$P(S=4)=P(\{(1,3),(2,2),(3,1)\})=\frac{\card(\{(1,3),(2,2),(3,1)\})}{\card(\{1,\dots,6\}^2)}=\frac{3}{36}.$$ 

On obtient :
\begin{center}
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|c|}
\hline
$k$ & 2 & 3& 4& 5& 6& 7& 8& 9& 10& 11& 12 \\\hline
$p_k=P(S=k)$ & $\frac{1}{36}$ & $\frac{2}{36}$& $\frac{3}{36}$& $\frac{4}{36}$& $\frac{5}{36}$& $\frac{6}{36}$& $\frac{5}{36}$& $\frac{4}{36}$& $\frac{3}{36}$& $\frac{2}{36}$& $\frac{1}{36}$\\\hline
\end{tabular}.
\end{center}
Sa représentation graphique est :
\begin{center}
\includegraphics[width=8cm]{somme.png}
\end{center}
\end{Ex}


\begin{Th}[Construire un espace de probabilité à partir d'une loi]
Soit $(x_1,\dots,x_n)$ une famille finie de réels et $(p_1,\dots,p_n)$ une famille de réels positifs telle que $\sum_{i=1} p_i = 1$.\\
Alors il existe un
espace probabilisé $(\Omega ,\mathcal{P}(\Omega) ,P)$ et une variable aléatoire  $X$ sur cette espace et à valeurs dans  $\{x_1,\dots,x_n\}$ telle que : 
$$ \forall i \in \Intf{1}{n}:\quad  P( X = x_i ) = p_i.$$
\end{Th}
\begin{proof}
Soit $\Omega=\{x_1,\dots,x_n\}$ et $P$ la probabilité définie sur $(\Omega,\mathcal{P}(\Omega))$ par :
$$P(\{x_i\})=p_i,\quad\forall i \in\Intf{1}{n}.$$
Soit $X$ l'application identité. On vérifie que   $P( X = x_i )=P(\{x_i\})=p_i$, pour tout $i\in \Intf{1}{n}.$ 
\end{proof}
\begin{NB}
Ce théorème permet de définir une variable aléatoire par sa loi de probabilité sans avoir à étudier l'expérience aléatoire sous-jacente, c'est à dire définir l'espace de probabilité $(\Omega,\mathcal{P}(\Omega),P)$ et la fonction de la variable aléatoire. Par exemple, on modélise l'expérience aléatoire d'un lancer de dé en posant : la variable aléatoire $X$ représente le chiffre du dé avec $p_1=p_2=p_3=p_4=p_5=p_6=\frac{1}{6}$.    
\end{NB}
\begin{DfProp}[Fonction d'une variable aléatoire]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini et $X$ une variable aléatoire réelle sur cette espace.\\
Soit $f:\R\to \R$ une application quelconque.\\
L'application \defi{$f\circ  X$}
\[ \Fonction{f\circ  X}{\Omega}{\R}{\omega}{f(X(\omega))} \]
est une variable aléatoire réelle.\\
L'usage veut qu'on la note abusivement $f(X)$ au lieu de $f\circ X$.\\
\begin{center}
\begin{tikzpicture}[scale=1]
\node (set1) at (0,0) {$\Omega$};
\node (set2) at (2,0) {$\R$};
\node (set3) at (4,0) {$\R$};
\draw[->] (set1) -- (set2)node[midway,above]{$X$};
\draw[->] (set2) -- (set3)node[midway,above]{$f$};
\draw[->] (set1) to[bend right]node[midway,below]{$f\circ X$} (set3);
\end{tikzpicture}
\end{center}
On a $$\forall y\in f(X)(\Omega):\quad P(f(X)=y)=\sum_{x\in X(\Omega) \text{ tel que }f(x)=y }P(X=x)= \sum_{i\in\Intf{1}{n} \text{ tel que }f(x_i)=y }P(X=x_i).$$  
\end{DfProp}
\begin{Ex}[Jeu]
Le gain obtenu est fonction de la somme obtenue avec les deux dés. La modélisation est d'appliquer une fonction à la somme, $s$, des dés  : 
 \[ \Fonction{G}{\Intf{2}{12}}{\{-1,0,2\}}{s}{\begin{cases}2&\text{ si }s=2 \text{ ou } 12\\-1&\text{ si }s=7\\0 &\text{ sinon} \end{cases}}.\]
 La variable aléatoire Gain est $G\circ X$.\\ 
Vérifions sur un exemple la modélisation. Si le jet des dés donne $\omega=(1,6)$, le gain de -1.
 On a bien $G\circ S(\omega=(1,6))=G(S(1,6))=G(1+6)=G(7)=-1$.\\
La loi de probabilité $S$ est déterminé par :
\begin{center}
\begin{tabular}{|c||c|c|c|}
\hline
$k$ & -1 &  2&0\\\hline
$P(G(S)=k)$ & $\frac{6}{36}=P(S=7)$ & $\frac{2}{36}=P(S=2)+P(S=12)$& $\frac{28}{36}=1-P(G(S)=-1)+P(G(S)=2)$  \\\hline
\end{tabular}
\end{center} 
\end{Ex}

%


\subsection{Vecteurs aléatoires}
\begin{DfProp}[Loi conjointe]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini et $X,Y$ deux variables aléatoires réelles sur cette espace.\\
On note  $(X,Y)$ le \defi{couple de variables aléatoires} prenant ses valeurs dans $\R^2$.\\
La \defi{loi conjointe} du couple $(X,Y)$ est déterminé par  :
\begin{enumerate}
\item $X(\Omega)\times Y(\Omega)=\{x_1,\dots,x_n\}\times \{y_1,\dots,y_m\} $, les valeurs prises par le couple
\item $\forall (i,j)\in \{1,\dots,n\}\times \{1,\dots,m\}:\quad P(X=x_i\cap Y=y_j).$
\end{enumerate}
On note $p_{i,j}=P(X=x_i\cap Y=y_j)$.\\
Les événements $((X=x_i)\cap (y=y_j))_{\forall (i,j)\in \{1,\dots,n\}\times \{1,\dots,m\}}$ forment un système complet d'événements de $\Omega$. En particulier, on a : 
$$\sum_{i=1}^n \sum_{j=1}^mP(X=x_i\cap Y=y_j)=\sum_{i=1}^n \sum_{j=1}^m p_{i,j}=1.$$ 
\end{DfProp}
\begin{proof}
Soit $(A,B)\subset X(\Omega)\times Y(\Omega)$. Il existe $I\subset\Intf{1}{n}$ et $J\subset\Intf{1}{m}$ tel que $A=\{x_i:i\in I\}$ et $B=\{y_j:j\in J\}$.\\ On a :
$$P((X,Y)\in (A,B))= P( X\in A\cap Y\in B )= P(\bigcup_{i\in I} (X=x_i)\cap  \bigcup_{j\in J} (Y=y_j) )=P(\bigcup_{i\in I,j\in J} (X=x_i)\cap (Y=y_j) ) \overbrace{=}^{ (\{(X=x_i)\cap (Y=y_j)\})_{i\in I,j\in J }\text{ disjoints}}\sum_{i\in I,j\in J}P(X=x_i\cap Y=y_j).$$ 
  
\end{proof}

\begin{Df}[Lois marginales]
Soit $X,Y$ deux variables aléatoires réelles définies sur $(\Omega,\mathcal{P}(\Omega),P)$.\\
La loi de $X$ appelé \defi{première loi marginale} et la loi de $Y$ \defi{second loi marginale} du couple.
\end{Df}
\begin{Prop}[Relations]
Soit $X,Y$ deux variables aléatoires réelles définies sur $(\Omega,\mathcal{P}(\Omega),P)$. On a :
$$\forall i\in \{1,\dots,n\}: \quad P(X=x_i)=\sum_{j=1}^{m }P((X=x_i)\cap (Y=y_j))$$
et 
$$\forall j\in \{1,\dots,m\}: \quad P(Y=y_j)=\sum_{i=1}^{n }P((X=x_i)\cap (Y=y_j)).$$ 

\begin{center}
\begin{tabular}{|c|ccccc|c|c}
\cline{1-7}
\backslashbox{$X$}{$Y$} & $y_1$ &$\dots$ & $y_j$&$\dots$&$y_m$&$P(X=x_i)$\\\cline{1-7}
$x_1$ & $p_{1,1}$ &$\dots$ & $p_{1,j}$&$\dots$&$p_{1,m}$&$P(X=x_1)$\\
$\vdots$ & $\vdots$ &  & $\vdots$& &$\vdots$&$\vdots$\\
$x_i$ & $p_{i,1}$ &$\dots$ & $p_{i,j}$&$\dots$&$p_{i,m}$&$P(X=x_i)$&$\leftarrow\sum_{k=1}^m p_{i,k}$ \\
$\vdots$ & $\vdots$ &  & $\vdots$& &$\vdots$&$\vdots$\\
$x_n$ & $p_{n,1}$ &$\dots$ & $p_{n,j}$&$\dots$&$p_{n,m}$&$P(X=x_n)$\\\cline{1-7}
$P(Y=y_j)$& $P(Y=y_1)$&$\dots$&$P(Y=y_j)$&$\dots$&$P(Y=y_m)$&1\\\cline{1-7}
      & & &$\overset{\uparrow}{\sum_{k=1}^n p_{k,j}}$ & & &\\
\end{tabular}
\end{center} 
\end{Prop}


\begin{Ex}
 On tire deux nombres au hasard dans $\{-1,1\}$. On note $X$ leur somme, et $Y$ leur produit. On cherche à déterminer la loi conjointe de $(X,Y)$. L'univers est $\{-1;1\}^2$, que $X$ prend ses valeurs dans $\{-2,0,2\}$ et $Y$ dans $\{-1,1\}$. Les variables aléatoires étant discrètes, il suffit de déterminer toutes les probabilités $P(X=x\text{  et }Y=y$) pour tout couple $(x,y)\in \{-1;1\}^2$. On a :
 \begin{itemize}
 \item $P(X=2, Y=1)=1/4$(correspond au cas on on tire 1 et 1).
 \item $P(X=2, Y=-1)=0.$
\item  $P(X=0, Y=1)=0.$
\item  $P(X=0, Y=-1)=1/2.$
\item $P(X=-2, Y=1)=1/4.$
\item $P(X=-2, Y=-1)=0.$
 \end{itemize}

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\backslashbox{$X$}{$Y$} & -1& 1 & $P(X=x)$\\\hline
-2 & 1/4& 0 & 1/4\\\hline
0 & 0& 1/2 & 1/2\\\hline
2 & 1/4& 0 & 1/4\\\hline
$P(Y=y)$&1/2&1/2&1 \\\hline
\end{tabular}
\end{center} 
\end{Ex}
\begin{Ex}
Dans une classe, la répartition en fonction de l'age et du genre est :
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\backslashbox{Age}{Genre} & Fille& Garçon & Total\\\hline
18 & 5 & 10& 15 \\\hline
19 & 2 & 6& 8 \\\hline
20 & 0 & 1 & 1 \\\hline
Total&7&17&24 \\\hline
\end{tabular}
\end{center}
On tire au hasard un élève dans la classe.\\
$X$ représente l'age de l'élève.\\
$Y$ représente le genre de l'élève avec la label 0 pour une fille et le label 1 pour un garçon.\\
La loi de probabilité conjointe $(X,Y)$ est déterminé par :
 \begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\backslashbox{$X$}{$Y$} & 0& 1 & $P(X=x)$\\\hline
18 & 5/24& 10/24 & 15/24\\\hline
19 & 2/24& 6/24 & 8/24\\\hline
20 & 0/24& 1/24 & 1/24\\\hline
$P(Y=y)$&7/24&17/24&1 \\\hline
\end{tabular}
\end{center} 

\end{Ex}

%% -----------------------------------------------------------------------------
\subsection{Indépendance et lois conditionnelles}
\begin{Df}[Lois conditionnelles]
Soit $(X,Y)$ un couple de variables aléatoires sur $(\Omega,\mathcal{P}(\Omega),P)$.\\
\begin{enumerate}
\item On appelle \defi{loi conditionnelle} de $X$ sachant $(Y = y_j )$ pour $P(Y = y_j )\neq 0$, la probabilité définie par  :
$$\forall i\in \{1,\dots,n\}:\quad  P_{Y=y_j}(X=x_i)=\frac{P(X=x_i\cap Y=y_j) } {P(Y=y_i)}$$ 
\item On appelle \defi{loi conditionnelle} de $Y$ sachant $(X = x_i )$ pour $P(X = x_i )\neq 0$, la probabilité définie par  :
$$\forall j\in \{1,\dots,m\}:\quad  P_{X=x_i}(Y=y_j)=\frac{P(X=x_i\cap Y=y_j) } {P(X=x_i)}$$ 
\end{enumerate}
\end{Df}

\begin{NB}
Les lois marginales et les lois conditionnelles déterminent la loi conjointe :
$$\forall (i,j)\in \{1,\dots,n\}\times \{1,\dots,m\}:\quad P(X=x_i\cap Y=y_j)=P_{X=x_i}(Y=y_j)P(X=x_i)$$
$$\forall (i,j)\in \{1,\dots,n\}\times \{1,\dots,m\}:\quad P(X=x_i\cap Y=y_j)=P_{Y=y_j}(X=x_i)P(Y=y_j)$$
\end{NB}
\begin{Df}[Indépendance]
Soit $(X,Y)$ un couple de variables aléatoires sur $(\Omega,\mathcal{P}(\Omega),P)$.\\
On dit que $X$ et $Y$ sont \defi{indépendantes} si 
$$ \forall (i,j)\in \{1,\dots,n\}\times \{1,\dots,m\}:\quad P(X=x_i\cap Y=y_j):\quad P( (X=x_i)\cap (Y=y_j) ) = P(X=x_i) P(Y=y_j).$$
\end{Df}
\begin{NB} Dans la modélisation d'une expérience aléatoire, l'hypothèse d'indépendance des variables aléatoires est souvent une donnée de l'expérience et 
non pas une propriété à vérifier. Par exemple, la modélisation de l'expérience du jeter de deux dés serait :
\begin{itemize}
\item $X_1$,  la variable aléatoire représentant le chiffre du premier dé,
\item $X_2$, la variable aléatoire représentant le chiffre du second dé,
\item $X_1$ et $X_2$, supposées indépendantes,
\item $S=X_1+X_2$, la somme des deux dés.
\end{itemize}
\end{NB}
\begin{Th}
Soit $(X,Y)$ un couple de variables aléatoires sur $(\Omega,\mathcal{P}(\Omega),P)$.\\
Si $X$ et $Y$ sont indépendantes, il en va de même pour les variables aléatoires $f(X)$ et $g(Y)$
où $f:\R\to \R$ et $g:\R\to \R $ sont deux applications quelconques.
\end{Th}




%% -----------------------------------------------------------------------------
\subsection{Espérance}
L'espérance mathématique d'une variable aléatoire réelle est la moyenne pondérée par les probabilités d'apparition de chaque valeur. Le théorème de la loi forte des grands nombres démontrera que l'espérance est la valeur que l'on s'attend à trouver, en moyenne, si l'on répète un grand nombre de fois la même expérience aléatoire.
\begin{Df}[Espérance d'une variable aléatoire]
Soit $X$ une valeur aléatoire réelle.\\
L'\defi{espérance de $X$} est
\[ E(X) = \sum_{\forall i\in \{1,\dots,n\} } x_i P(X=x_i) \]
\end{Df} 
\begin{Ex}[Somme de deux dés]
Reprenons l'exemple du lancer de deux dés en notant $S$ la somme des chiffres obtenus. 
L'espérance de $S$ vaut alors :
$$E(S ) = \sum_{s\in S (\Omega)} sP(S = s)=  2.\frac{1}{36}+3.\frac{2}{36}+4.\frac{3}{36}+5.\frac{4}{36}+6.\frac{5}{36}+7.\frac{6}{36}+8.\frac{5}{36}+9.\frac{4}{36}+10.\frac{3}{36}+11.\frac{2}{36}+12.\frac{1}{36}=7.$$
\end{Ex}


\begin{Th}[Formule de transfert]
Si $X$ est une variable aléatoire réelle
 et $f:\R\to \R$, alors
\[ E(f(X)) =  \sum_{\forall i\in \{1,\dots,n\} }  f(x_i) P(X=x_i). \]
\end{Th}

\begin{NB}
La formule de transfert permet de  calculer $E(f(X))$ sans avoir à déterminer la loi de $f(X)$.\\
Dans l'exemple du jeu, l'espérance de la variable aléatoire $G(X)$ représente le gain  moyen du joueur. On applique la formule du transfert :
\[E(G(S))=\sum_{s\in \{2,3,\dots,12\}}  G(s) P(S=s)=2P(S=2)-1P(S=7)+2P(S=12)=2\frac{1}{36}-1\frac{6}{36}+2\frac{2}{36}=-\frac{1}{18}.\]
En conclusion, ce jeu n'est pas favorable au joueur.
\end{NB}

%\begin{proof}
%Soit $X(\Omega)=\{x_1,x_2,\dots,x_n\}$ les valeurs prises par la variables aléatoires.\\
%Les événements $X^{-1}(x_1),\dots,X^{-1}(x_n)$ est un système complet d'événements. On a :
%\begin{align*}
% E(X) &= \sum_{\omega\in\Omega} X(\omega) P(\{\omega\})\\
% &= \sum_{\omega\in \cup_{i=1}^{n}X^{-1}(x_i)} X(\omega) P(\{\omega\})\\
%  &= \sum_{x\in \{x_1,x_2,\dots,x_n\} } \sum_{\omega \in X^{-1}(x)} X(\omega) P(\{\omega\})\\
%    &= \sum_{x\in \{x_1,x_2,\dots,x_n\} } \sum_{\omega \in X^{-1}(x)} x P(\{\omega\})\\
%    &= \sum_{x\in \{x_1,x_2,\dots,x_n\} }  x \sum_{\omega \in X^{-1}(x)} P(\{\omega\})\\
%      &= \sum_{x\in X(\Omega) }  x P(X=x)
%\end{align*} 
%\end{proof}

\begin{Th}
Soit $X$ et $Y$ deux variables aléatoires indépendantes.\\
Alors \[ E(XY) = E(X) E(Y). \]
\end{Th}
\begin{proof}
On applique le théorème de transfert à la variable aléatoire $f(X,Y)=XY$ d'où
\begin{align*}
 E(XY) &= \sum_{ \forall (i,j)\in \{1,\dots,n\}\times \{1,\dots,m\} } x_i y_j P(X=x_i\cap Y=y_j )\\
       &\overbrace{=}^{\text{indépendance} } \sum_{  \forall (i,j)\in \{1,\dots,n\}\times \{1,\dots,m\} } x_i y_j P(X=x_i) P(Y=y_j)\\
       &= \sum_{ i=0 }^n  \sum_{j=0}^m  x_i y_j P(X=x_i) P(Y=y_j)\\
       &= \sum_{ i=0 }^n  x_i P(X=x_i) \sum_{j=0}^m y_j  P(Y=y_j) \\
       &= E(X)E(Y).
\end{align*} 
\end{proof}
\begin{Df}[Centrée]
Une variable aléatoire est dite \defi{centrée} si son espérance est nulle.
\end{Df}

\begin{Prop}[propriétés de l'espérance]
Soit $X$ et $Y$ deux variables aléatoires réelles et $(a,b)\in\R^2$.
\begin{itemize}
\item
  $E(a) = a$.
\item
  $E(aX+bY) = aE(X)+bE(Y)$.
\item
  Si $P(X\geq 0)=1$, alors $E(X)\geq 0$.
\item
  Si $P(X\leq Y)=1$, alors $E(X)\leq E(Y)$.
\end{itemize}
\end{Prop}
\begin{Ex}[Centrée une variable aléatoire]
Soit $X$ une variable aléatoire.\\
Alors la variable aléatoire $Y=X-E(X)$ est centrée car $E(Y)=E(X-E(X))=E(X)-E(E(X))=E(X)-E(X)=0$
\end{Ex}

%


\subsection{Variance}




La variance est une mesure de la dispersion des valeurs d'une loi de probabilité.
\begin{Df}[variance d'une variable aléatoire]

Soit $X$ une variable aléatoire réelle.
Sa \defi{variance} est $E\left( (X-E(X))^2\right)$ et on la note $V(X)$.
Son \defi{écart-type} est $\sigma(X) =\sqrt{V(X)}$.
\end{Df}
\begin{Prop}[Formule de K\oe nig-Hugens]
Soit $X$ une variable aléatoire réelle.
Pour tout $a>0$, on a
\[ V(X) = E(X^2)-(E(X))^2 \]
\end{Prop}
\begin{Ex}[Somme de deux dés]
Reprenons l'exemple du lancer de deux dés en notant $S$ la somme des chiffres obtenus. 
On a :
$$E(S^2 )\overbrace{=}^{thransfert} \sum_{s\in S (\Omega)} s^2P(S = s)=  2^2.\frac{1}{36}+3^2.\frac{2}{36}+4^2.\frac{3}{36}+\dots+12^2.\frac{1}{36}=\frac{329}{6}.$$
La variance de $S$ vaut alors :
$$V(S)=E(S^2 )-(E(S))^2=\frac{329}{6}-7^2=\frac{35}{6}.$$
et son écart-type
$$\sigma(S)=\sqrt{V(S)}\approx 2,42.$$
\end{Ex}


\begin{Df}[Covariance de deux variables aléatoires]

Soit $X$ et $Y$ deux variables aléatoires réelles.
Leur \defi{covariance} est $E( (X-E(X)) (Y-E(Y)) )$ et on la note $\mathrm{Cov}(X,Y)$.
\end{Df}
\begin{Prop}[Propriétés]

Soit $X$ et $Y$ deux variables aléatoires réelles.
\begin{itemize}
\item
  $V(aX+b) = a^2V(X)$.
\item
  Si $X$ et $Y$ sont indépendantes, alors $V(X+Y) =V(X)+V(Y)$.
\item
  $Var(X+Y) = Var(X) + Var(Y) + 2\mathrm{Cov}(X,Y)$.
\end{itemize}
\end{Prop}

\begin{Df}[Corrélation]

Soit $X$ et $Y$ deux variables aléatoires réelles de variance non nulles.
Leur \defi{coefficient de corrélation} est
\[ \rho(X,Y) = \frac{\mathrm{Cov}(X,Y)}{\sigma(X)\sigma(Y)} \]
\end{Df}


\begin{Prop}[Propriétés]

Soit $X$ et $Y$ deux variables aléatoires réelles de variance non nulles.
\begin{itemize}
\item
  $\rho(X,Y) \in [-1,1]$
\item
  $\rho(X,Y) = ±1$ si et seulement si il existe deux réels $a$ et $b$ tels que l'événement $(Y=aX+b)$ soit certain.
\item
  Si $X$ et $Y$ sont indépendantes, alors $\rho(X,Y) = 0$. On dit qu'elles sont décorrélées.
  La réciproque est fausse.
\end{itemize}
\end{Prop}
%% -----------------------------------------------------------------------------
\subsection{Lois usuelles}

\begin{Df}[Loi uniforme]

Une variable aléatoire réelle $X$ suit la \defi{loi uniforme} sur $\{1,2,\dots,n\}$
si 
\begin{enumerate}
\item $X(\Omega)=\{1,2,\dots,n\}$,
\item $\forall k\in \{1,2,\dots,n\}:\quad  P(X=k) = \frac{1}{n}.$ 
\end{enumerate} 
On note $X \hookrightarrow \mathcal{U}(E)$.\\
On a : $E(X)=\frac{n+1}{2}$ et $V(X)=\frac{n^2-1}{2}$.
\end{Df}

\begin{Df}[Loi de Bernoulli]
Une variable $X$ à valeurs dans $\{0,1\}$ suit la \defi{loi de Bernoulli} de paramètre $p$
si 
\begin{enumerate}
\item $X(\Omega)=\{0,1\}$,
\item $P(X=1) = p \quad \text{et} \quad P(X=0) = 1-p.$ 
\end{enumerate} 
On note $X \hookrightarrow  \mathcal{B}(p)$.\\
On a : $E(X)=p$ et $V(X)=p(1-p)$.
\end{Df}
\begin{Prop}[Loi indicatrice]
Soit $A$ est un événement de $\Omega$. La variable aléatoire réelle $1_A$ définie par  
$$1_A(\omega) =\begin{cases}1\text{ si }\omega \in A\\0\text{ si }\omega \in \bar A \end{cases}$$
est une variable de Bernoulli de paramètre $p=P(A)$. On l'appelle \defi{loi indicatrice} de l'événement $A$.
\end{Prop}
\begin{Df}[Loi binomiale]
Une variable $X$ à valeurs dans $\{0,n\}$ suit la \defi{loi binomiale} de paramètres $n$ et $p$
si
\begin{enumerate}
\item $X(\Omega)=\{0,1,2\dots,12\}$,
\item $\forall k\in\{0,1,\dots,n\},\quad P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}.$ 
\end{enumerate} 
On note $X \hookrightarrow  \mathcal{B}(n,p)$.\\
On a : $E(X)=np$ et $V(X)=np(1-p)$.
\end{Df}
\begin{NB}
Pour $n=1$, on retrouve la loi de Bernouilli de paramètre $p$.
\end{NB}
\begin{Prop}[Loi des tirages avec remise]
Soit $X_1, X_2,\dots, X_n$ $n$ variables aléatoires indépendantes de loi de Bernoulli de même paramètre $p$.\\
Alors $S=X_1+ X_2+\dots+ X_n$ suit une loi binomiale de paramètres $n, p$.\\
En d'autres termes, si l'expérience aléatoire est  une répétition de $n$ épreuves identiques et indépendantes tel que chaque épreuve est une expérience Bernouilli de paramètre  $p$ et si $S$ est égale au nombre de succès des $n$ épreuves de l'expérience, alors $S$  suit une loi binomiale de paramètres $n, p$.\\    
\end{Prop}


\subsection{Convergence et approximations}

%\begin{Prop}[Approximation d'une loi binomiale par une loi de Poisson]
%Soit $(X_n)_{n\in\N}$ une suite de variables aléatoires tel que $X_n\hookrightarrow \mathcal{B}(n,p_n)$ et $\lim\limits_{n\to\infty}np_n=\lambda$.\\
%Alors on a :
%$$\forall k \in \N:\quad  \lim\limits_{n\to\infty} P(X_n = k) = e^{-\lambda}\frac{\lambda^k}{k!}.$$
%\end{Prop}
%\begin{proof}
%Soit $k\in \N$. On a :
%\begin{align*}
%P(X_n = k) &= \begin{pmatrix}n \\ k \end{pmatrix} (p_n)^k (1-p_n)^{n-k}\\
%&= \frac{1}{k!} n.(n-1).\dots (n-k+1)(p_n)^k (1-p_n)^{n-k} \\
%&= \frac{1}{k!} 1.(1-1/n).\dots (1-(k+1)/n)(p_n/n)^k (1-p_n)^{n-k} \\
%\end{align*}
%D'une part  $\overbrace{1.(1-1/n).\dots (1-(k+1)/n)}^{k \text{ facteurs fixes}}\tend[n\to+\infty]1$, d'autre part $(p_n/n)^k\tend[n\to+\infty] \lambda^k$ et enfin $(1-p_n)^{n-k}=e^{(n-k)\ln(1-p_n)}\tend[n\to+\infty] e^{-\lambda}$ car $(n-k)\ln(1-p_n)\equivalent[n\to+\infty] -np_n$. Finalement
%$$\lim\limits_{n\to\infty} P(X_n = k) = e^{-\lambda}\frac{\lambda^k}{k!}.$$
%\end{proof}
%%TODO DEMO
%
%%TODO loi faible des grands nombres
%% Rajouter 
%En pratique, si $X$ est une variable aléatoire suivant la loi binomiale $\mathcal{B}(n,p)$ avec $n\geq 30$, $p\leq 0,10$ et $np\geq 15$, on peut approximer la loi de $X$ par la loi de Poisson de paramètre $np$.\\
%Ce théorème  justifie le fait que la loi de Poisson est utilisée comme modèle de certaines expériences aléatoires (nombre de clients entrant dans un magasin, nombre de coquilles dans une page de journal,...).

\begin{Prop}[Inégalité de Markov]
Soit $X$ une variable aléatoire réelle positive.\\
Pour tout $a > 0$, on a :
\[ P(X\geq a) \leq \frac{E(X)}{a}.\]
\end{Prop}
\begin{Prop}[Inégalité de Bienaymé-Tchebychev]
Soit $X$ une variable aléatoire réelle.
Pour tout $a>0$, on a
\[ P( |X-E(X)| \geq a ) \leq \frac{V(X)}{a^2} \]
\end{Prop}
%TODO FAIRE LES DEMOS
Cette inégalité présente un intérêt théorique en majorant la
probabilité qu'une variable aléatoire s'écarte de sa moyenne. Nous allons l'utiliser pour prouver la loi faible des grands
nombres.

Lors d'un lancer d'une pièce de monnaie équilibrée, les deux côtés « pile » et « face » apparaissent de façon équiprobable pour des raisons de symétrie : on ne s'attend pas plus à l'un ou à l'autre côté. Cette mesure de l'attente s'appuie souvent sur une considération statistique : on observe que la fréquence des occurrences de chaque côté se rapproche de 1/2. 
\begin{center}
\includegraphics[width=8cm]{frequence_lancer.png}
\end{center}
Le théorème de la loi des grands nombres permet de justifier ce résultat en interprétant la probabilité comme une fréquence de réalisation.\\
La modélisation de cette expérience aléatoire est :
\begin{enumerate}
\item  \textbf{n\up{ième} lancer} :  pour tout $n\in\N^*$,  la variable aléatoire $X_n$, représente le résultat du n\up{ième} lancer. Elle  suit une loi Bernouilli de paramètre $p$ (l'issue 0 représente le pile et l'issue 1 le face). Elles sont supposées indépendantes.  On a $E(X_n) = (1 - p).0 + p.1  = p.$ 
\item \textbf{fréquence} : pour tout $n\in\N^*$,  la variable aléatoire $S_n$, représente la moyenne des résultats obtenus au cours des n premiers lancers, soit :
$$ S_n =\frac{X_1+X_2+\dots+X_n}{n}$$ 
\end{enumerate}
L'issue, $\omega$, correspondant à une succession de faces existe, $X_n(\omega)=1$ pour tout $n\in \N^*$. Donc $1$ est une valeur possible de la variable aléatoire $S_n$. Cependant, le théorème de la loi faible des grands nombres prouve que la probabilité que $S_n$ s'écarte de l'espérance $E(X_n)$ tend vers 0 quand $n$ tend vers l'infini. 
\begin{Th}[Loi faible des grands nombres]
Soit $(X_n)_{n\in\N^*}$ une suite de variables aléatoires discrètes définies sur un espace probabilisé $(\Omega,\mathcal{A} ,P)$. On
suppose toutes les variables indépendantes et de même loi, admettant une espérance $m$ et un écart
type $\sigma$. Posons $S_n =\frac{X_1+X_2+\dots+X_n}{n}.$\\
Alors 
$$ \forall \epsilon>0: \quad P\left(\left| S_n - m \right|\geq \epsilon \right )\tend[n\to+\infty]0.$$
\end{Th}
\begin{proof}
D'après l'inégalité de Bienaymé-Tchebychev et par indépendance des variables aléatoires,
$$ \forall \epsilon>0: \quad P\left(\left| S_n - m \right|\geq \epsilon\right)\leq \frac{V(S_n)}{\epsilon^2}=\frac{\frac{V(X_1+X_2+\dots+X_n)}{n^2}}{\epsilon^2}=\frac{\sigma^2}{n\epsilon^2} \tend[n\to+\infty]0.$$
\end{proof}
\begin{NB}
Le TP Python \url{https://github.com/VincentTariel/cours/blob/master/probabilite/simulation_variable_aleatoire_avtivite_python.pdf} permet de vous familiariser avec ce théorème sur des applications.
\end{NB}
