\documentclass[a4paper]{book}
\usepackage{t1enc}
\usepackage[latin1]{inputenc}
\usepackage[french]{minitoc}
 \usepackage{amsmath}
\usepackage{fancyhdr,amsmath,amsthm,amssymb,fancybox}
\usepackage[francais]{babel}
\usepackage{amsmath}
\usepackage{TikZ}
\usetikzlibrary{shapes,backgrounds}
\usepackage{tkz-fct}   
\usepackage{a4wide,jlq2eams} 
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{slashbox}
\usepackage{thmbox}
\usepackage{xcolor}
\usepackage{sectsty}
\usepackage{longtable} 
\definecolor{amaranth}{rgb}{0.9, 0.17, 0.31}
\sectionfont{\color{magenta}}
\subsectionfont{\color{red}}
\subsubsectionfont{\color{red}}
\newcommand{\defi}[1]{\textbf{\textcolor{orange}{#1}}}

\setlength{\shadowsize}{1.5pt}
 
\pagestyle{fancy}
\addtolength{\headwidth}{\marginparsep}
\addtolength{\headwidth}{\marginparwidth} 
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\fancyhf{}
\fancyhead[LE,RO]{\bfseries\thepage}
\fancyhead[LO]{\bfseries\rightmark}
\fancyhead[RE]{\bfseries\leftmark}
\fancypagestyle{plain}{%
   \fancyhead{} % get rid of headers
   \renewcommand{\headrulewidth}{0pt} % and the line
}

\setcounter{minitocdepth}{3}



\thmboxoptions{S,bodystyle=\itshape\noindent}
\newtheorem[L]{Lem}{Lemme}[section]
\newtheorem[L]{Th}[Lem]{Théorème}
\newtheorem[L]{Cor}[Lem]{Corollaire}
\newtheorem[L]{Prop}[Lem]{Proposition}

\newtheorem[S,bodystyle=\upshape\noindent]{Df}{Définition}
\newtheorem[S,bodystyle=\upshape\noindent]{Ex}{Exemple}
\newtheorem[S,bodystyle=\upshape\noindent]{NB}{Remarque}
\newtheorem[S,bodystyle=\upshape\noindent]{intr}{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\E}{(-4,-1) rectangle (4,4);\node[above right] at (-4,-1) {$\Omega$};}
\newcommand{\A}{(0,0) ++(135:2) circle (2);\node at (-1.4,-0.75) {$A$};}
\newcommand{\B}{(0,0) ++(45:2) circle (2);\node at (1.4,-0.75) {$B$};}
\newcommand{\AuB}{(0,0) arc(-135:135:2) arc(45:315:2);\node at (0,1.5) {$A\cup B$};}
\newcommand{\AnB}{(0,0) arc (-45:45:2) arc (135:225:2);\node at (0,1.5) {$A\cap B$};}



\begin{document}



\chapter{Probabilité finie}




%\dominitoc
La théorie des probabilités fournit des modèles mathématiques permettant
l'étude d'expériences dont le résultat ne peut être prévu avec une totale
certitude.

\begin{center}

\begin{tabular}{| p{6.5cm}| p{6.5cm} |p{1.7cm} |}
\hline
Expérience & Univers  $\Omega$ (ensemble des issues) & cardinal\\
\hline \hline 
Lancer d'un dé & Un entier $k\in\{1,\dots,6\}$&finie \\
\hline
Prélèvement de n objets en sortie d'une chaîne de production dans l'échantillon & Nombre d'objets défectueux, $k\in\{0,\dots,n\}$&finie\\
\hline
Questionnaire à 100 questions  binaires & Suite $\omega$ de 100 réponses $\omega\in\{oui, non\}^{100}$&finie\\
\hline
Lancer d'une pièce jusqu'à la première obtention de pile & Un entier $k \in \mathbb{N}$ : le temps d'attente du premier succès&dénombrable\\
\hline
Temps d'attente pour une hotline  & un temps $\omega\in [0,+\infty[$&continue\\
\hline
Mouvement d'un grain de pollen dans un liquide & Une fonction continue : la trajectoire $f:\mathbb{R}^+\to\mathbb{R}^2$&continue  \\
\hline
Mouvement d'un cours boursier & Une fonction continue : $f:\mathbb{R}^+\to\mathbb{R}$&continue\\
\hline
 \end{tabular}
\end{center}
Bien que le résultat précis de chacune de ces expériences soit imprévisible,
l'observation et l'intuition nous amènent à penser que ces phénomènes
obéissent à certaines lois. Par exemple si on jette 6000 fois le dé, on s'attend
à ce que le nombre d'apparitions de la face « 3 » soit voisin de 1000. Si on
met en service 100 ampoules, leurs durées de vie observées seront concentrées
autour d'une certaine valeur moyenne.\\
La théorie des probabilités modélise l'expérience aléatoire dans un cadre formel en quantifiant le sentiment d'incertitude vis-à-vis d'un événement. La \textit{statistique} permet de confronter les modèles probabilistes avec la réalité observée afin de les valider ou de les invalider. Par
exemple si quelqu'un a 60 bonnes réponses sur 100 au questionnaire, est-il
légitime de considérer qu'il a « mieux fait » que le hasard ?\\
Dans le cadre de cours, on limite l'univers à un ensemble finie, c'est à dire que l'on peut effectuer une énumération finie des issues de l'expérience aléatoire.    
 

\section{Modélisation probabilistes pour un univers fini}
\subsection{Axiomes des probabilité. Premières propriétés}
\begin{Df}[Univers]
Un \defi{univers}, noté $\Omega$, est l'ensemble de toutes les \defi{issues} (résultats) qui peuvent être obtenues au cours d'une expérience aléatoire. Une issue est noté $\omega$. Dans toute la suite de cours, on suppose que $\Omega$ est fini. 
\end{Df}
\begin{Ex}[Lancer de un dé]
Pour l'expérience aléatoire du lancer d'un dé, l'univers est $\Omega=\{1,2,3,4,5,6\}$. 
\end{Ex}


\begin{Df}[Événement]
Un \defi{événement} est une partie de l'univers. Un événement est dit \defi{élémentaire} si il contient une unique issue.
\end{Df} 
\begin{Ex}
Pour l'expérience aléatoire du lancer d'un dé, l'événement A "Obtenir un chiffre pair" est l'ensemble $\{2,4,6\}$. Il n'est pas élémentaire car il est composé de trois issues : 2, 4 et 6.
\end{Ex}

\begin{Df}[Notions et opérations]
Les notions et opérations que l'on définit sur les événements correspondent aux notions et opérations  que l'on définit sur les ensembles.
\begin{center}
\begin{longtable}{|p{1.4cm}|l|p{3cm}|l|}
\hline
Notations&	Vocabulaire ensembliste&	Vocabulaire probabiliste& Diagramme de Venn	\\
\hline
\hline
$\emptyset$&	ensemble vide&	événement impossible&	\\
\hline
$\Omega$&	ensemble plein&	événement certain& \begin{tikzpicture}[scale=0.5]\fill[color=cyan] \E;\draw \E;\end{tikzpicture}	\\
\hline
$\omega$&	élément de $\Omega$& issue&\begin{tikzpicture}[scale=0.5]\draw \E;\node[above right] at (0,0) {$\omega$};\node at (0,0) {$\bullet$};\end{tikzpicture}	\\
\hline
$\{\omega\}$&	singleton&	événement élémentaire&	\\
\hline
$A$&	sous-ensemble de $\Omega$&	événement& \begin{tikzpicture}[scale=0.5]
\draw  \E;
\fill[color=cyan]  \A;
\draw  \A;
\end{tikzpicture}		\\
\hline
$\omega\in A$&	 $\omega$ appartient à $A$&	 Le résultat $\omega$ est une des réalisations possibles de $A$	&	\begin{tikzpicture}[scale=0.5]
\draw  \E;
\draw  \A;
\node[above right] at (-1,0) {$\omega$};\node at (-1,0) {$\bullet$};
\end{tikzpicture}\\
\hline
 $A\subset B$&	 $A$ est inclus dans $B$&	 $A$ implique $B$&\begin{tikzpicture}[scale=0.5]
\draw  \E;
\draw (0.3,0.3) ++(45:2) circle (1);\node at (1.4,0.75) {$A$};
\draw  \B;
\end{tikzpicture}	\\
\hline
 $A\cup B$&	réunion de $A$ et $B$&	 $A$ ou $B$	& \begin{tikzpicture}[scale=0.5]
\draw  \E;
\fill[color=cyan]  \AuB;
\draw  \A;
\draw  \B;
\end{tikzpicture}\\
\hline
 $A\cap B$&	intersection de $A$ et $B$&	 $A$ et $B$&\begin{tikzpicture}[scale=0.5]
\draw  \E;
\draw  \A;
\draw  \B;
\fill[color=cyan]  \AnB;
\end{tikzpicture}
 	\\
\hline
 $\bar A$ (noté aussi $A^{c}$)&	complémentaire de $A$ dans  $\Omega$	&	événement contraire de $A$&\begin{tikzpicture}[scale=0.5]
\fill[color=cyan]  \E;
\fill[color=white]  \A;
\draw  \A;
\node at (2,0) {$\bar A$};
\end{tikzpicture}	\\
\hline
 $ A\cap B=\emptyset$&	 $A$ et $B$ sont disjoints&	$A$ et $B$ sont incompatibles&\begin{tikzpicture}[scale=0.5]
\draw  \E;
\draw  \A;
\draw (1.5,0) ++(45:2) circle (1);\node at (2.4,0) {$B$};
\end{tikzpicture}	\\
\hline
\end{longtable}
\end{center}
\end{Df} 

\begin{Df}[Tribu]
L'ensemble des événements possibles appelé \defi{tribu} est l'ensemble des parties de l'univers, soit $\mathcal{P}(\Omega)$.
\end{Df}
\begin{Ex}
Pour le lancer d'une pièce, l'univers est $\{P,F\}$ et la tribu est $ \{\varnothing, \{P \}, \{F \}, \{P, F \} \}$.
\end{Ex}

\begin{Df}[Espace probabilisable]
Le couple $(\Omega,\mathcal{P}(\Omega))$ est appelé \defi{espace probabilisable}.
\end{Df}

\begin{Df}[Axiomes des probabilités]
Soit $(\Omega,\mathcal{P}(\Omega))$ un espace probabilisable fini.
Une \defi{probabilité} sur $(\Omega,\mathcal{P}(\Omega))$ est une application
de $\mathcal{P}(\Omega)$ dans $\R^+$ vérifiant :
\begin{itemize}
\item
  $P(\Omega)=1$.
\item
  Pour deux événements disjoints $A$ et $B$, on a  :
$$P(A\cup B)=P(A)+P(B)$$  
\end{itemize}
Le triplet  $(\Omega,\mathcal{P}(\Omega),P)$ s'appelle un \defi{espace probabilisé}.
\end{Df}



%TODO faire les diagrammes de VEIN
\begin{Prop}
\begin{enumerate}
\item $ P(\emptyset)=0.$
\item Pour tout $A,B\in \mathcal{A}$ tel que  $A\subset B$, on a :
$$P(A)\leq P(B)$$
$$P(B\setminus A )=P(B)-P(A)$$
\item Pour tout $A\in \mathcal{A}$, on a $P(A)\in[0,1]$.
\item Pour tout $A,B\in \mathcal{A}$, on a $$P(A\cup B)+P(A\cap B)=P(A)+P(B).$$
\item Pour tout $A,B\in \mathcal{A}$, on a $$P(A\cap B)\leq P(A)+P(B).$$
\item Si $A_1, \dots, A_n$ est une famille d'événements deux à deux incompatibles, alors
alors \[ P\left( \cup_{i=1}^n A_i \right) = \sum_{i=1}^n P(A_i) \]
\item \defi{Sous additivité} :Si $A_1, \dots, A_n$ est une famille d'événements , alors  :
\[ P\left( \cup_{i=1}^n A_i \right) \leq  \sum_{i=1}^n P(A_i) \]
\end{enumerate}
\end{Prop}
\begin{proof}
\begin{enumerate}
\item Les deux événements  $\Omega$ et $\emptyset$ sont disjoints d'où :
\begin{align*}
P(\Omega)=&P(\Omega\cup \emptyset )\\
P(\Omega)=&P(\Omega)+P(\emptyset)\\
P(\emptyset)=&0.
\end{align*}
\item Comme $A\subset B$, on a  $A \bigcup\limits_{\text{disjoints}}(B\setminus A)=B$, d'où :
$$ P(A)+P(B\setminus A)=P(B)$$
et 
$$ P(A)\leq P(B)$$
\item Comme $A\subset \Omega$, on a $P(A)\leq P(\Omega)=1$.
\item Comme $A\cup B=(A\setminus (A\cap B))\bigcup\limits_{\text{disjoints}}B$, on a $$P(A\cup B)=P(A\setminus (A\cap B))+P(B).$$ Comme $(A\cap B)\subset A$, on a bien : 
 $$P(A\cup B)=P(A)- P(A\cap B)+P(B).$$
\item Comme $P(A\cup B)+ P(A\cap B)=P(A)+P(B)$, on a $P(A\cup B)\leq P(A)+P(B)$.
\item Démonstration par récurrence :\\
Soit $H_n$ la propriété si $A_1, \dots, A_n$ est une famille d'événements deux à deux incompatibles,
alors \[ P\left( \cup_{i=1}^n A_i \right) = \sum_{i=1}^n P(A_i) \].
\begin{itemize}
\item $H_1$ : on a bien  $P(A)=P(A)$.
\item $H_n\Rightarrow H_{n+1}$ : Soit $A_1, \dots, A_n, A_{n+1}$ une famille d'événements deux à deux incompatibles. On a:
\begin{align*}
P\left( \cup_{i=1}^{n+1} A_i \right)&=P(\left( \cup_{i=1}^{n} A_i \right)\cup A_{n+1} )\\
&=P\left( \cup_{i=1}^{n} A_i \right)+ P (A_{n+1} ) \text{ car } \cup_{i=1}^{n} A_i \text{ et } A_{n+1} \text{ sont disjoints} \\
&= \sum_{i=1}^n P(A_i)+ P (A_{n+1} ) \text{ car } H_n \\
&= \sum_{i=1}^{n+1} P(A_i).
\end{align*}
\end{itemize}
\item Démonstration identique à la précédente en remplaçant les égalités par inégalités.
\end{enumerate}
\end{proof}

\begin{Df}[Probabilité uniforme]
On appelle \defi{probabilité uniforme} sur $\Omega$ la probabilité définie par :
$$P(A)=\frac{card(A)}{card(\Omega)}.$$
\end{Df}

\begin{Ex}[Lancer de deux dés]
Pour l'expérience aléatoire du lancer de deux dés, l'univers est $\Omega=\overbrace{\{1,2,3,4,5,6\}}^{\text{Issues du premier dé}}\times \overbrace{\{1,2,3,4,5,6\}}^{\text{Issues du second dé}}$ et la probabilité est la probabilité uniforme.\\
L'événement A: "Somme des chiffres égale à 2 ou 12" est $\{(1,1),(6,6)\}$.\\
L'événement B: "Somme des chiffres égale à 7" est $\{(1,6),(2,5),(3,4),(4,3),(5,2),(6,1)\}$. \\
D'où
$$P(A)=\frac{card(A)}{card(\Omega)}=\frac{2}{36}=\frac{1}{18},$$
et
 $$P(B)=\frac{card(B)}{card(\Omega)}=\frac{6}{36}=\frac{1}{6}.$$
\end{Ex}

\begin{Prop}
Une probabilité $P$ sur un univers fini est complètement déterminée par les $P(\{\omega\})$ pour tout $\omega \in \Omega$. $P(\{\omega\})$, appelé poids de probabilité.\\
En effet, pour $A \subset \Omega$, on a :
\begin{align*}
P(A)&=P(\bigcup\limits_{\omega\in A}\{w\} ),\\
 &=\sum_{\omega\in A}P(\{w\}).
\end{align*}
\end{Prop}
\begin{NB}
\begin{itemize}
\item Les poids d'une probabilité $P$ vérifient
$$ \sum_{\omega \in \Omega}P(\{\omega\}) = 1.$$
\item Il est souvent plus facile de définir une probabilité sur les événements élémentaires ("les issues") que sur l'ensemble des événements.\\
Une probabilité sur $\Omega=\{\omega_1,\ldots,\omega_n\}$ est la donnée d'une suite finie $(p_1,\ldots,p_n)$ de nombres tels que :
\begin{enumerate}
\item $p_i = P(\{\omega_i\})$
\item $0\leq p_i\leq 1$
\item $p_1+p_2+\ldots+p_n=1.$
\end{enumerate}
\end{itemize}
\end{NB}
\begin{Ex}
Une dé est pipé tel que la chance d'obtenir le chiffre 6 soit 2 fois plus grande que les autres chiffre. Dans ce cas, on a donc :
$$\begin{cases}
p_6=2 p_1=2 p_2=2 p_3=2 p_4=2 p_5 \\
p_1+p_2+p_3+p_4+p_5+p_6=1
\end{cases}$$
Après résolution, la probabilité est donc définie par
$$p_1=p_2=p_3=p_4=p_5=\frac 1 7 \text{ et }  p_6=\frac 2 7.$$
\end{Ex}



\begin{Df}[système complet d'événements]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.\\
Un \defi{système complet d'événements}, appelé aussi \defi{partition}, est une famille $(A_1,\ldots,A_n)$
d'événements deux à deux incompatibles tels que
\[ \bigcup\limits_{i=1}^n A_i = \Omega . \]
\begin{center}
\begin{tikzpicture}[scale=0.75]

%\fill[color=cyan!50] (0,1.5) ellipse (2.5 and 2);
\fill[red] (-3,-1) rectangle (-1,2);\node at (-2,1.5) {$A_1$};
\fill[opacity=0.5,green] (-1,-1) rectangle (1,2);\node at (0,1.5) {$A_2$};
\fill[opacity=0.5,yellow] (1,-1) rectangle (3,2);\node at (2,1.5) {$A_3$};
\draw (-3,-1) rectangle (3,2);\node[above right] at (-3,-1) {$\Omega$};
\end{tikzpicture}\\
$A_1,A_2,A_3$ est un système complet d'événements de $\Omega$.
\end{center}
\end{Df}
\begin{NB}[$A,\bar A$]
Pour tout événement $A$, $A,\bar A$ est un système complet d'événements.
\end{NB}
\begin{Prop}[système complet d'événements]
\label{prop:sce}
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.\\
Soit$(A_1,\ldots,A_n)$ un système complet d'événements.\\
On a :
\[ 1 = \sum_{i=1}^n P(A_i). \]
Pour tout événement $B$, on a
\[ P(B) = \sum_{i=1}^n P(B\cap A_i). \]
\begin{center}
\begin{tikzpicture}[scale=0.75]
\draw (-3,-1) rectangle (3,4);\node[above right] at (-3,-1) {$\Omega$};
\fill[color=cyan!80] (0,1.5) ellipse (3 and 1.5);
\fill[opacity=0.5,red] (-3,-1) rectangle (-1,4);\node at (-2,3.5) {$A_1$};
\fill[opacity=0.5,green] (-1,-1) rectangle (1,4);\node at (0,3.5) {$A_2$};
\fill[opacity=0.5,yellow] (1,-1) rectangle (3,4);\node at (2,3.5) {$A_3$};
\node at (0,1.5) {$A_2\cap B$};
\node at (-2,1.5) {$A_1\cap B$};
\node at (2,1.5) {$A_3\cap B$};
\node at (0,-0.4) {$B$};
\end{tikzpicture}
\end{center}

\end{Prop}

\begin{NB}
En particulier, pour tout événement $A$, on a :
$$P(A)+P(\bar A)=1$$
et pour tout événement $B$, :
$$P(B) = P(B\cap A)+P(B\cap\bar A)$$
\end{NB}


\begin{proof}
On a :
\begin{align*}
P(B)&=P(B\cap \Omega )\\
P(B)&=P(B\cap \left(\bigcup\limits_{i=1}^n A_i\right ) )\\
P(B)&=P(\bigcup\limits_{i=1}^n (B\cap A_i))\\
P(B)&=\sum_{i=1}^n P(B\cap A_i).
\end{align*}
En particulier si $B=\Omega$, on a :
\begin{align*}
P(\Omega)&=\sum_{i=1}^n P(\Omega\cap A_i)\\
1&=\sum_{i=1}^n P(A_i)
\end{align*}
\end{proof}
\begin{NB}
Un système complet d'événements intervient dans la modélisation d'une expérience aléatoire à plusieurs étapes comme dans l'exemple ci-dessous.  
\end{NB}
\begin{Ex}[3 urnes]
On dispose de 3 urnes $U_1$, $U_2$, $U_3$, chacune contient 10 boules; parmi elles, $U_1$ contient 1 blanche, $U_2$ contient 2 blanches, et $U_3$ contient 6 blanches. On tire au hasard une urne puis  une boule dans cette urne. Quelle est la probabilité de l'événement B:"obtenir une blanche" ?\\
Les événements $U_1$: "tirer l'urne 1,  $U_2$: "tirer l'urne 2", $U_3$::"tirer l'urne 3" sont un système complet d'événements. On a donc :
$$P(B)= P(B\cap U_1)+P(B\cap U_2)+P(B\cap U_3).$$
Il reste à déterminer les probabilité de cette somme ce qui est l'objet des probabilités conditionnelles.
\end{Ex}

\subsection{Probabilité conditionnelle}
Dans l'expérience aléatoire des trois urnes, la probabilité de tirer une boule blanche est modifié si l'on dispose de l'information l'urne 1 a été choisie.\\   
Le concept de probabilité conditionnelle permet de prendre en compte ce complément d'information.\\
Par exemple, une classe est constituée de $N$ élèves, dont 
\begin{enumerate}
\item $N_h$ hommes,
\item $N_m$ majeurs,
\item $N_{h\cap m}$ hommes et majeurs.
\end{enumerate}
Un élève passant au tableau est choisi aléatoirement. \\
On note $H=$"élève choisi est un homme" et  $M=$"élève choisi est majeur".\\
L'équiprobabilité donne  :
$$ P(M) = \frac{N_m}{N}\text{ et } P(H\cap M)=\frac{N_{h\cap m}}{N}.$$
Quelle est la probabilité que l'élève choisie soit un homme sachant qu'il doit être majeur, noté $P_M(H)$ ? 
Dans cette expérience aléatoire, l'information supplémentaire est l'élève choisi  est majeur. L'univers est maintenant l'ensemble des élèves majeurs donc la probabilité est :
$$P_M(H) =\frac{N_{h\cap m}}{N_m}.$$
Mais,
$$P_M(H) =\frac{N_{h\cap m}}{N_m}=\frac{\frac{N_{h\cap m}}{N}}{\frac{N_m}{N}}=\frac{P(H\cap M)}{P(M)}.$$ 
Par analogie, la définition formelle est :
\begin{Df}[Probabilité conditionnelle]

Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.
Soit $A$ un événement tel que $P(A)>0$.
L'application
\[ \Fonction{P_A}{\mathcal{P}(\Omega)}{[0,1]}{B}{\frac{P(A\cap B)}{P(A)}} \]
est une probabilité sur $(\Omega,\mathcal{P}(\Omega))$
appelée \defi{probabilité conditionnellement à $A$},
ou \defi{probabilité sachant $A$}.\\
On note $P(B|A) = P_A(B)$.
\end{Df}

\begin{Ex}
On lance un dé parfaitement équilibré. La probabilité d'obtenir un 6 est 1/6. On suppose maintenant que ce dé a ses faces impaires peintes en vert, et ses faces paires peintes en bleu. On a aperçu de loin que, sur le dessus du dé, on a obtenu une face bleue. Quelle est la probabilité d'obtenir 6 sachant une face bleue ?\\
On note $B=\{2,4,6\}$ l'événement "face bleue". On a :
$$P_B(\{6\})=\frac{P(\{6\}\cap B)}{P(B)}=\frac{\frac 1 6 }{\frac 1 2 }=\frac 1 3.$$
\end{Ex}


\begin{Prop}[Formule des probabilités totales]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.\\
Soit $(A_1,\ldots,A_n)$ un système complet d'événements de probabilités non nulles.\\
Pour tout événement $B$, on a
\[ P(B) = \sum_{i=1}^n P_{A_i}(B)P(A_i). \]
\end{Prop}
\begin{proof}
Dans l'équation d'un système complet d'événements  de la proposition~\ref{prop:sce}, il suffit de remplacer $P(B\cap A_i)$ pat $P(B|A_i)P(A_i).$
\end{proof}
\begin{Ex}[3 urnes]
La probabilité de tirer une boule blanche était de :
$$P(B)= P(B\cap U_1)+P(B\cap U_2)+P(B\cap U_3).$$
Ce qui donne :
$$P(B)= P_{U_1}(B)P(U_1)+P_{U_1}(B)P(U_2)+P_{U_3}(B)P(U_3)=\frac{1}{10} \frac 1 3+ \frac{2}{10} \frac 1 3 +\frac{3}{10} \frac 1 3 =\frac{6}{30} =\frac{1}{5} .$$
\end{Ex}
\begin{NB}
En particulier, si  $A$ est un événement de probabilité non nulle, on a pour tout événement $B$:
\[ P(B) = P_A(B)P(A) + P_{\bar A}(B)P(\bar A).\]
\end{NB}



\begin{Prop}[formule de Bayes]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.\\
Soit $A$ et $B$ deux événements de probabilités non nulles.\\
Alors
$$ P_B(A) = \frac{ P_A(B)P(A) }{ P(B) } $$
\end{Prop}
Cette formule permet d'inverser des conditions. Sa version simple découle de façon directe de la
définition d'une probabilité conditionnelle.
\begin{Prop}[formule de Bayes usuelle]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.
Soit $(A_1,\ldots,A_n)$ un système complet d'événements de probabilités non nulles.
Pour tout événement $B$ de probabilité non nulle,
et pour tout $k\in\{1,n\}$, on a
\[ P_B(A_k) = \frac{ P_{A_k}(B)P(A_k) }{ \sum_{i=1}^n P_{A_i}(B)P(A_i) }. \]
\end{Prop}

\begin{NB}
Le système $(A_1,\ldots,A_n)$ représente souvent une liste de causes pouvant amener l'événement B lors d'une étape
suivante de l'expérience par exemple dans le problème des 3 urnes. Il est alors généralement facile de déterminer la probabilité qu'une certaine
conséquence $B$ ait lieu, sachant que la cause $A_i$ a eu lieu, c'est-à-dire la probabilité conditionnelle
$P_{A_i}(B)$ en respectant l'ordre temporel. Ces données permettent, grâce à la formule de
Bayes, de remonter le temps, en déterminant la probabilité qu'une certaine cause $A_i$ ait eu lieu sachant
la conséquence $B$. Pour cette raison, cette formule est aussi souvent appelée formule de probabilité des
causes.
\end{NB}
\begin{Ex}[3 urnes]
On cherche à connaître la probabilité que l'urne 1 est été choisie sachant que l'on a tiré une boule blanche, c'est à dire $P_B(U_1)$.\\
On a donc 
$$ P_B(U_1) = \frac{ P_{U_1}(B)P(U_1) }{  P_{U_1}(B)P(U_1)+ P_{U_2}(B)P(U_2)+ P_{U_3}(B)P(U_3) }=\frac{\frac{1}{3}\frac{1}{10}}{\frac{1}{3}\frac{1}{10}+\frac{1}{3}\frac{2}{10}+\frac{1}{3}\frac{6}{10}}=\frac{1}{9}.$$
\end{Ex}


\begin{Ex}[Test de dépistage]
Vous êtes directeur de cabinet du ministre de la santé. Une maladie est présente dans la population, dans la proportion d'une personne malade sur 10000. Un responsable d'un grand laboratoire pharmaceutique vient vous vanter son nouveau test de dépistage : si une personne est malade, le test est positif à 99$\%$. Si une personne n'est pas malade, le test est positif à 0,1$\%$.
  Ces chiffres ont l'air excellent, vous ne pouvez qu'en convenir. Toutefois, avant d'autoriser la commercialisation de ce test, vous faites appel au statisticien du ministère : ce qui vous intéresse, ce n'est pas vraiment les résultats présentés par le laboratoire, c'est la probabilité qu'une personne soit malade si le test est positif. La formule de Bayes permet de calculer cette probabilité.\\
  On note M l'événement : "La personne est malade", et T l'événement : "Le test est positif". Le but est de calculer $P_T(M)$. Les données que vous avez en main sont $P(M)=0,0001$ (et donc $P(\bar M)=0,9999$), $P_M(T)=0,99$ et $P_{\bar M}(T)=0,001$. La formule de Bayes donne :
$$P_T( \bar M)=\frac{P_{\bar M}(T)P(\bar M)}{P_M(T)P(M)+P_{\bar M}(T)P(\bar M)}=\frac{0,9999×10^{-3}}{10^{-4}0,99+0,9999×10^{-3}}\approx 0,91.$$
C'est catastrophique! Il y a que 91$\%$ de chances qu'une personne positive au test ne soit pas malade! C'est tout le problème des tests de dépistage pour des maladies rares : ils doivent être excessivement performants, sous peine de donner beaucoup trop de "faux-positifs".
\end{Ex}


\begin{Df}[arbre de probabilité]
Un \defi{arbre de probabilité} est un schéma permettant de résumer une expérience aléatoire connaissant des probabilités conditionnelles, soit un graphe orienté et pondéré obéissant aux règles suivantes :
\begin{enumerate}
\item la somme des probabilités des branches issues d'un même sommet donne 1,
\item la probabilité d'un chemin est le produit des probabilités des branches qui le composent,
\item la probabilités de la branche allant du sommet A vers le sommet B est la probabilité conditionnelle de $B$ sachant que $A$ est déjà réalisé $P_A(B)$.
\end{enumerate}
On retrouve alors la propriété de la probabilité conditionnelle :
$$ P(A\cap B)= P_{A}(B)P(A).$$
Ainsi que la formule des probabilités totales, si $A_1, A_2, \dots , A_n$ définit un système complet d'évènements de probabilité non nulles, on a :
$$ P(B)=\sum _{i=1}^{n}P(B\cap A_{i})=\sum _{i=1}^{n} P_{A_{i}}(B)P(A_{i}).$$
\end{Df}
%
\begin{Ex}[3 urnes]
%
\begin{tikzpicture}[scale=1.5]
\draw (6.1,3) node[above]{\'Evénements};
\draw  (0,0)  -- (1.8,2) node[midway,sloped,above]{$P(U_1)=\frac 1 3 $};
\draw (2,2) node {$U_1$} ;
\draw  (2.2,2) -- (4.8,1.3)node[midway,sloped,above]{$P_{U_1}(\bar{B})=\frac{9}{10}$};
\draw (4.9,1.3) node[right] {$\bar{B}\quad U_1\cap \bar{B}$} ;    
\draw  (2.2,2) -- (4.8,2.7)node[midway,sloped,above]{$P_{U_1}(B)=\frac{1}{10}$};
\draw (4.9,2.7) node[right] {$B\quad U_1\cap B$} ;

\draw  (0,0) -- (1.8,0)node[midway,sloped,above]{$P(U_2)=\frac 1 3 $};
\draw (2,0) node {$U_2$} ;
\draw  (2.2,0) -- (4.8,-0.7)node[midway,sloped,above]{$P_{U_2}(\bar{B})=\frac{8}{10}$};
\draw (4.9,-0.7) node[right] {$\bar{B}\quad U_2\cap \bar{B}$} ;    
\draw  (2.2,0) -- (4.8,0.7)node[midway,sloped,above]{$P_{U_2}(B)=\frac{2}{10}$};
\draw (4.9,0.7) node[right] {$B\quad U_2\cap B$} ;

\draw  (0,0) -- (1.8,-2)node[midway,sloped,above]{$P(U_3)=\frac 1 3 $};
\draw (2,-2) node {$U_3$} ;
\draw  (2.2,-2) -- (4.8,-2.7)node[midway,sloped,above]{$P_{U_3}(\bar{B})=\frac{4}{10}$};
\draw (4.9,-2.7) node[right] {$\bar{B}\quad U_3\cap \bar{B}$} ;    
\draw  (2.2,-2) -- (4.8,-1.3)node[midway,sloped,above]{$P_{U_3}(B)=\frac{6}{10}$};
\draw (4.9,-1.3) node[right] {$B\quad  U_3\cap B$} ;
\end{tikzpicture}\\
La probabilité de  l'événement $B$ est la somme des probabilités des parcours
qui mènent à B, d'où 
$$P(B)= P_{U_1}(B)P(U_1)+P_{U_1}(B)P(U_2)+P_{U_1}(B)P(U_3).$$
\end{Ex}

% -----------------------------------------------------------------------------
\subsection{Indépendance}
On considère l'expérience aléatoire de lancer successivement deux fois un dé.\\
Soit  $A$ un événement relié au premier lancer, par exemple obtenir un chiffre pair sur le premier dé et 
soit  $B$ un événement relié au second lancer, par exemple obtenir un chiffre impair sur le second dé.
L'information de savoir que l'événement $A$ est réalisé, ne modifie pas la probabilité de l'événement $B$, autrement dit $P_A(B) = P(B)$. 
Mais, d'après la définition de la probabilité conditionnelle, on a : $P_A(B) =\frac{P(A\cap B)}{P(A)}$. De ces deux égalités, on obtient $P(A\cap B)=P(A)P(B)$ et on dit que les deux événements sont indépendants.\\ 
Par analogie, la définition formelle est :
\begin{Df}[indépendance]

Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.
\begin{itemize}
\item
  Deux événements $A$ et $B$ sont \defi{indépendants} si $P(A\cap B)=P(A)P(B)$.
\item
  Une famille $(A_1,\ldots,A_n)$ d'événements sont \defi{(mutuellement) indépendants}
  si pour toute partie $I\subset\{1,\ldots,n\}$, on a
  \[ P\left( \bigcap_{i\in I} A_i \right) = \prod_{i\in I} P(A_i).\]
\end{itemize}
\end{Df}
\begin{Ex}[Lancer de deux dés]
$A$="Obtenir 5 ou 6 sur le premier dé"\\
$A=\{(5,1),(5,2),(5,3),(5,4),(5,5),(5,6),(6,1),(6,2),(6,3),(6,4),(6,5),(6,6)\}$.\\
$B$="Obtenir  6 sur le second dé"\\
$B=\{(1,6),(2,6),(3,6),(4,6),(5,6),(6,6)\}$\\
$A\cap B=$"Obtenir 5 ou 6 sur le premier dé et obtenir  6 sur le second dé".\\
$A\cap B= \{ (5,6),(5,6),(6,6)\}.$
On a $P(A)=\frac{12}{36}=\frac 1 3 , P(B)=\frac{6}{36}=\frac 1 6$ et $P(A\cap B)=\frac{3}{36}=\frac{1}{12}= P(A)P(B)$.\\
Donc les événements $A$ et $B$ sont indépendants.
\end{Ex}

\begin{NB}
Trois événements peuvent être indépendants deux à deux, sans pour autant être mutuellement indépendants. 
Par exemple, on considère un dé équilibré à 4 faces ($\Omega=\{1,2,3,4\}$ avec $p_1=p_2=p_3=p_4=\frac 1 4$ et les événements :
$$A=\{1,2\},\quad B=\{1=3\},\quad C=\{1,4\}.$$
On a : $$P(A)=P(B)=P(C)=\frac 1 2$$ et $$P(A\cap B)=(A\cap C)=P(B\cap C)=P(\{1\})=\frac 1 4 =P(A)P(B)=P(A)P(C)=P(B)P(C).$$
Les événements $A$, $B$ et $C$ sont deux à deux indépendants mais :
 $$P(A\cap B\cap C )= P(\{1\})=\frac 1 4 \neq  \frac 1 8 =  P(A)P(B)P(C).$$
 Donc les événements ne sont pas mutuellement indépendants.
\end{NB}
\begin{Prop}[lien avec la probabilité conditionnelle]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.\\
Soit $A$ un événement de probabilité non nulle
et $B$ un événement quelconque.\\
Alors les événements $A$ et $B$ sont indépendants si et seulement si $P_A(B)=P(B)$.
\end{Prop}
\begin{proof}
Soit $A$ et $B$ deux événements tel que $P(A)\geq 0$.\\
\begin{align*}
A, B \text{ sont indépendants } & \Leftrightarrow P(B\cap A)=P(B)P(A)\\
& \Leftrightarrow \frac{P(B\cap A)}{P(A)}=P(B) \text{ car }P(A)\neq 0\\
& \Leftrightarrow P_A(B)=P(B).
\end{align*} 
\end{proof}

\begin{Prop}[Formule des probabilités composées]
Soit $A_1,A_2,\dots, A_n$ $n$ événements vérifiant $P(A_1\cap A_2\cap \dots \cap A_{n-1})\neq 0$.\\
Alors 
$$P(A_1\cap A_2\cap \dots \cap A_{n})=P(A_1)P_{A_1}(A_2)P_{A_1\cap A_2 }(A_3)\dots P_{A_1\cap A_2\cap \dots \cap A_{n-1}}(A_n).$$
\end{Prop}
\begin{tikzpicture}[scale=1.5]
\node (start) at (0,0) {$\Omega$};
\node (A1) at (1.5,1) {$A_1$};
\node (A1f) at (1.5,0) {};
\node (A2) at (3,2) {$A_2$};
\node (A2f) at (3,1) {};
\node (A3) at (4.5,3) {};
\node (A3f) at (4.5,2) {};
\node (A4) at (7.2,3) {$A_3:\quad P(A_1\cap A_2\cap A_{3})=P(A_1)P_{A_1}(A_2)P_{A_1\cap A_2 }(A_3)$};
\draw(start) -- (A1)node[midway,sloped,above]{$P(A_1)$};
\draw[dashed] (start) -- (A1f);
\draw(A1) -- (A2)node[midway,sloped,above]{$P_{A_1}(A_2)$};
\draw[dashed] (A1) -- (A2f);
\draw(A2) -- (A3)node[midway,sloped,above]{$P_{A_3}(A_1\cap A_2)$};
\draw[dashed] (A2) -- (A3f);
\end{tikzpicture}\\
\begin{proof}
Il suffit de remonter le temps : 
$$P(A_1\cap A_2\cap \dots \cap A_{n})=P(A_1\cap A_2\cap \dots \cap A_{n-1}) P_{A_1\cap A_2\cap \dots \cap A_{n-1}}(A_n).$$
Puis :
$$P(A_1\cap A_2\cap \dots \cap A_{n})=P(A_1\cap A_2\cap \dots \cap A_{n-2}) P_{A_1\cap A_2\cap \dots \cap A_{n-2}}(A_{n-1})P_{A_1\cap A_2\cap \dots \cap A_{n-1}}(A_n).$$
On itère jusqu'à $A_1$.
\end{proof}


%TODO voir cours de mpsi sur les méthodes



\section{Variable aléatoire}

\begin{Ex}[Jeu]Pour attirer les clients, un casino propose un nouveau jeu : le croupier lance simultanément 2 dés et calcule leur somme,
\begin{itemize} 
\item si la somme est égale à 2 ou 12, le joueur gagne 2 euros,
\item si la somme est égale à 7, le casino gagne 1 euro,
\item dans les autres cas, c'est nul (le joueur gagne 0 euro).  
\end{itemize}
A votre avis, ce jeu est-il favorable au joueur ou au casino ? A chaque partie quelle est le gain moyen du joueur ?
\end{Ex}
%TODO modif extrait de suret 
Dans ce jeu, on fait intervenir le hasard en observant la somme des points marqués par deux dés. Considérons le jet d'un dé bleu et d'un dé
rouge et notons $S$ la somme des points obtenus. On modélise cette expérience
en prenant l'équiprobabilité sur l'univers  
$$\Omega=\{1,2,3,4,5,6\}^2=\overbrace{\{1,2,3,4,5,6\}}^{\text{Issues du premier dé}}\times \overbrace{\{1,2,3,4,5,6\}}^{\text{Issues du second dé}}.$$
Une issue, $\omega$, est un couple $(b, r)$ où b désigne le chiffre du
dé bleu et r celui du rouge. La somme $S$ est l'application :
$$\Fonction{S}{\Omega}{\{2,3,\dots,12\} }{(b, r)}{b+r}$$ 
Cette application est représenter par ce tableau  : 
\begin{center}
\begin{tabular}{c||c|c|c|c|c|c}
 \backslashbox{$b$}{$r$} & 1 & 2&3&4&5&6 \\\hline\hline
1 & 2 & 3 & 4&5&6&7\\
2 & 3 & 4 & 5&6&7&8\\
3 & 4 & 5 & 6&7&8&9\\
2 & 5 & 6 & 7&8&9&10\\
1 & 6 & 7 & 8&9&10&11\\
2 & 7 & 8 & 9&10&11&12\\
\end{tabular}
\end{center}
On dit que S est une variable aléatoire sur $\{2,3,\dots,12\}$.
En fait, l'observation qui nous intéresse dans cette expérience, ce n'est pas $\omega$,  mais seulement $S(\omega)$. On aimerait connaître la probabilité que
la somme des points prenne une valeur donnée, soit $P(S = k)$ pour $k$ entier
fixé entre 2 et 12. En utilisant l'équiprobabilité sur et le tableau ci-dessus, on obtient 
\begin{center}
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|c|}
\hline
$k$ & 2 & 3& 4& 5& 6& 7& 8& 9& 10& 11& 12 \\\hline
$P(S=k)$ & $\frac{1}{36}$ & $\frac{2}{36}$& $\frac{3}{36}$& $\frac{4}{36}$& $\frac{5}{36}$& $\frac{6}{36}$& $\frac{5}{36}$& $\frac{4}{36}$& $\frac{3}{36}$& $\frac{2}{36}$& $\frac{1}{36}$\\\hline
\end{tabular}
\end{center}
Cela revient à considérer un nouvel univers :
$$\Omega'=\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}$$
et à munir cet ensemble de la probabilité $P_S$ définie par le tableau des $P(S =
k)$. Cette nouvelle probabilité s'appelle loi de la variable aléatoire S.
\subsection{Généralités}
\begin{Df}[variable aléatoire]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini.\\
Une \defi{variable aléatoire} est une application : $$\Fonction{X}{\Omega}{E}{\omega}{X(\omega)}.$$
Lorsque $E=\R$, on parle de \defi{variable aléatoire réelle}.\\
On note $X(\Omega)=\{X(\omega):\omega \in \Omega \}$ l'ensemble des images de la variable aléatoire.
\end{Df}

\begin{Df}[événements associés à une variable aléatoire]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.\\
Soit $X$ une variable aléatoire à valeurs dans $E$.\\
Pour tout $A\subset E$, on définit l'événement $\{ X \in A \}$ comme étant
\[ X^{-1}(A) = \{\omega\in\Omega :   X(\omega )\in A\}. \]
\begin{itemize}
\item  On notera plus simplement "$X=A$" pour "$\{ X\in A \}$".
\item Si $A = \{k\}$, on notera "$X=k$" pour "$\{ X\in A\}$".
\item Si $E =\R$ et $A = ]-\infty,a]$, on notera  "$X\leq a$"  pour "$\{ X\in A\}$" etc.
\end{itemize}
\end{Df}
\begin{Ex}[Jeu]
Par exemple, l'ensemble des issues donnant une somme à 7 est :
$$\{S=7\}= S^{-1}(\{7\})=\{(1,6),(2,5),(3,4),(4,3),(5,2),(6,1)\}.$$
et l'ensemble des issues donnant une somme à 2 ou 12 est :
$$\{S\in \{2,12\}\}= X^{-1}(\{2,12\})=\{(1,1),(6,6)\}.$$
\end{Ex}
\begin{Df}[loi d'une variable aléatoire]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini.\\
Soit $X$ une variable aléatoire à valeurs dans l'ensemble $E$ fini.\\
L'application
\[ \Fonction{P_X}{\mathcal{P}(E)}{[0,1]}{A}{P(X^{-1}(A))} \]
est une probabilité sur $E$, appelée \defi{loi de la variable $X$}.
\end{Df}

\begin{Prop}[Déterminer une loi]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini.\\
Soit $X$ une variable aléatoire.\\
Déterminer la \defi{la loi de probabilité $P_X$} de la variable aléatoire $X$, c'est donner
\begin{enumerate}
\item l'ensemble $X(\Omega)=\{x_1,\dots,x_n\}$ des valeurs prises par $X$,
\item pour chaque $x_i$ de $X(\Omega)$, la probabilité $p_i=P(X=x_i)$. 
\end{enumerate} : 
\end{Prop}
\begin{proof}
La démonstration repose sur $$\forall A \subset \mathcal{P}(E): \quad P(X\in A)=P(\underbrace{\bigcup_{x\in A\cap X(\Omega)  }}_{disjoints} (X=x))=\sum_{x\in A}P(X=x).$$
\end{proof}
\begin{Prop}
\begin{itemize}
\item $\forall x\in X(\Omega):\quad p_i=\sum_{\omega\in\Omega \text{ tel que }X(\omega)=x_i}P(\{\omega\})$,
\item Les événements $X=x_1,X=x_2,\dots,X=x_n$ forme un système complet d'événements de $\Omega$ et donc :
$$\sum_{x_i\in X(\Omega)}P(X=x_i)=\sum_{i=1}^n p_i=1.$$
\end{itemize}  
\end{Prop}
\begin{Ex}[Jeu]
La  fonction $S:\{1,\dots,6\}^2\to \{2,\dots,12\}$ est déterminée par ce tableau  :
\begin{center}
\begin{tabular}{c||c|c|c|c|c|c}
 \backslashbox{$b$}{$r$} & 1 & 2&3&4&5&6 \\\hline\hline
1 & 2 & 3 & 4&5&6&7\\
2 & 3 & 4 & 5&6&7&8\\
3 & 4 & 5 & 6&7&8&9\\
2 & 5 & 6 & 7&8&9&10\\
1 & 6 & 7 & 8&9&10&11\\
2 & 7 & 8 & 9&10&11&12\\
\end{tabular}
\end{center}
Du fait de l'équiprobabilité, on détermine la loi de probabilité $S$ en calculant le nombre de cases. Par exemple,
$$P(S=4)=P(\{(1,3),(2,2),(3,1)\})=\frac{Card(\{(1,3),(2,2),(3,1)\})}{Card(\{1,\dots,6\}^2)}=\frac{3}{36}.$$ 

On obtient :
\begin{center}
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|c|}
\hline
$k$ & 2 & 3& 4& 5& 6& 7& 8& 9& 10& 11& 12 \\\hline
$p_k=P(S=k)$ & $\frac{1}{36}$ & $\frac{2}{36}$& $\frac{3}{36}$& $\frac{4}{36}$& $\frac{5}{36}$& $\frac{6}{36}$& $\frac{5}{36}$& $\frac{4}{36}$& $\frac{3}{36}$& $\frac{2}{36}$& $\frac{1}{36}$\\\hline
\end{tabular}.
\end{center}
\end{Ex}



\begin{Df}[fonction d'une variable aléatoire]
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé.\\
Soit $X$ une variable aléatoire à valeurs dans $E$.\\
Soit $f:E\to F$ une application quelconque.
L'application ,
\[ \Fonction{f\circ  X}{\Omega}{F}{\omega}{f(X(\omega))} \]
est une variable aléatoire à valeurs dans $F$.
L'usage veut qu'on la note abusivement $f(X)$ au lieu de $f\circ X$.\\
\begin{center}
\begin{tikzpicture}[scale=1]
\node (set1) at (0,0) {$\Omega$};
\node (set2) at (2,0) {$E$};
\node (set3) at (4,0) {$F$};
\draw[->] (set1) -- (set2)node[midway,above]{$X$};
\draw[->] (set2) -- (set3)node[midway,above]{$f$};
\draw[->] (set1) to[bend right]node[midway,below]{$f\circ X$} (set3);
\end{tikzpicture}
\end{center}
On a $$P(f(X)=y)=\sum_{x\in X(\Omega)\text{ tel que }f(x)=y }P(X=x)$$  
\end{Df}
\begin{Ex}[Jeu]
Le gain obtenu est fonction de la somme obtenue avec les deux dés. La modélisation est d'appliquer une fonction à la somme, S, des dés  : 
 \[ \Fonction{G}{\{2,3,\dots,12\}}{\{-1,0,2\}}{s}{\begin{cases}2&\text{ si }s=2 \text{ ou } 12\\-1&\text{ si }s=7\\0 &\text{ sinon} \end{cases}}.\]
 La variable aléatoire Gain est $G\circ X$.\\ 
Vérifions sur un exemple la modélisation. Si le jeté des dés donne $\omega=(1,6)$, le gain de -1. On a $G\circ S(\omega=(1,6))=G(S(1,6))=G(1+6)=G(7)=-1$.\\
La loi de probabilité $S$ est déterminé par :
\begin{center}
\begin{tabular}{|c||c|c|c|}
\hline
$k$ & -1 &  2&0\\\hline
$P(G(S)=k)$ & $\frac{6}{36}=P(S=7)$ & $\frac{2}{36}=P(S=2)+P(S=12)$& $\frac{28}{36}=1-P(G(S)=-1)+P(G(S)=2)$  \\\hline
\end{tabular}
\end{center} 
\end{Ex}

%
%% -----------------------------------------------------------------------------
\subsection{Indépendance}

\begin{Df}
Soit $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini.\\
Soit $X$ une variable aléatoire à valeurs dans $X(\Omega)$ et $Y$ une variable aléatoire à valeurs dans $Y(\Omega)$.
On dit que $X$ et $Y$ sont \defi{indépendantes} si 
$$  \forall x\in X(\Omega), \forall y\in Y(\Omega),\quad P( (X=x)\cap (Y=y) ) = P(X=x) P(Y=y).$$
\end{Df}
\begin{NB} Dans la modélisation d'une expérience aléatoire, l'hypothèse d'indépendance des variables aléatoires est souvent une donnée de l'expérience et 
non pas une propriété à vérifier. Par exemple, la modélisation de l'expérience du jeter des deux dés serait :
\begin{itemize}
\item $X_1$,  la variable aléatoire représentant le chiffre du premier dé,
\item $X_2$, la variable aléatoire représentant le chiffre du second dé,
\item $X_1$ et $X_2$, supposées indépendantes,
\item $S=X_1+X_2$, la somme des deux dés.
\end{itemize}

\end{NB}

\begin{Th}
Soit  $(\Omega,\mathcal{P}(\Omega),P)$ un espace probabilisé fini.\\
Soit $X$ une variable aléatoire à valeurs dans $E$ et $Y$ une variable aléatoire à valeurs dans $F$.
Si $X$ et $Y$ sont indépendantes, il en va de même pour les variables aléatoires $f(X)$ et $g(Y)$
où $f:E\to E'$ et $g:F\to F'$ sont deux applications quelconques.
\end{Th}

\subsection{Loi conjointe, loi marginale}
\begin{Df}[Loi conjointe]
Soit $X,Y$ deux variables aléatoires réelles définies sur $(\Omega,\mathcal{P}(\Omega),P)$.\\
On note  $(X,Y)$ le \defi{couple de variables aléatoires} prenant ses valeurs dans $\R^2$.\\
La \defi{loi conjointe} du couple $(X,Y)$ est déterminé par  :
\begin{enumerate}
\item $X(\Omega)\times Y(\Omega)=\{x_1,\dots,x_n\}\times \{y_1,\dots,y_m\} $, les valeurs prises par le couple
\item $\forall (x,y)\in X(\Omega)\times Y(\Omega): P(X=x\cap Y=y)$,
\end{enumerate}
On note $p_{i,j}=P(X=x_i\cap Y=y_j)$.\\
Les événements $((X=x)\cap (y=y))_{(x,y)\in X(\Omega)\times Y(\Omega)}$ forment un système complet d'événements de $\Omega$. En particulier, on a : 
$$\sum_{\forall (x,y)\in X(\Omega)\times Y(\Omega)}P(X=x\cap Y=y)=\sum_{i=1}^n \sum_{j=1}^m p_{i,j}=1.$$ 
\end{Df}
\begin{Df}[Lois marginales]
Soit $X,Y$ deux variables aléatoires réelles définies sur $(\Omega,\mathcal{P}(\Omega),P)$.\\
La loi de $X$ appelé \defi{première loi marginale} et la loi de $Y$ \defi{second loi marginale} du couple.
\end{Df}
\begin{Prop}[Relations]
Soit $X,Y$ deux variables aléatoires réelles définies sur $(\Omega,\mathcal{P}(\Omega),P)$. On a :
$$\forall x\in X(\Omega): P(X=x)=\sum_{y\in Y(\Omega)}P((X=x)\cap (Y=y))$$
et 
$$\forall j\in Y(\Omega): P(Y=y)=\sum_{i\in X(\Omega)}P((X=x)\cap (Y=y)).$$ 

\begin{center}
\begin{tabular}{|c|ccccc|c|c}
\cline{1-7}
\backslashbox{$X$}{$Y$} & $y_1$ &$\dots$ & $y_j$&$\dots$&$y_m$&$P(X=x)$\\\cline{1-7}
$x_1$ & $p_{1,1}$ &$\dots$ & $p_{1,j}$&$\dots$&$p_{1,m}$&$P(X=x_1)$\\
$\vdots$ & $\vdots$ &  & $\vdots$& &$\vdots$&$\vdots$\\
$x_i$ & $p_{i,1}$ &$\dots$ & $p_{i,j}$&$\dots$&$p_{i,m}$&$P(X=x_i)$&$\leftarrow\sum_{k=1}^m p_{i,k}$ \\
$\vdots$ & $\vdots$ &  & $\vdots$& &$\vdots$&$\vdots$\\
$x_n$ & $p_{n,1}$ &$\dots$ & $p_{n,j}$&$\dots$&$p_{n,m}$&$P(X=x_n)$\\\cline{1-7}
$P(Y=y)$& $P(Y=x_1)$&$\dots$&$P(Y=x_j)$&$\dots$&$P(Y=x_m)$&1\\\cline{1-7}
      & & &$\overset{\uparrow}{\sum_{k=1}^n p_{k,j}}$ & & &\\
\end{tabular}
\end{center} 
\end{Prop}
\begin{Df}[Loi conditionnelle]
Soit $X,Y$ deux variables aléatoires réelles définies sur $(\Omega,\mathcal{P}(\Omega),P)$.\\
Pour tout $x\in X(\Omega)$ fixé avec $P(X=x)>0$, on appelle  \defi{loi conditionnelle} de $Y$ sachant $(X=x)$ la probabilité définie par :
$$\forall y\in Y(\Omega): \quad P_{X=x}(Y=y)=\frac{P(X=x\cap Y=y)}{P(X=x)}$$
\end{Df}
\begin{NB}
Les lois marginales et les lois conditionnelles déterminent la loi conjointe :
$$\forall (x,y)\in X(\Omega)\times Y(\Omega):\quad P(X=x\cap Y=y) =P_{X=x}(Y=y)P(X=x)$$
$$\forall (x,y)\in X(\Omega)\times Y(\Omega):\quad P(X=x\cap Y=y) =P_{Y=y}(X=x)P(Y=y)$$
\end{NB}

\begin{Ex}
 On tire deux nombres au hasard dans $\{-1,1\}$. On note $X$ leur somme, et $Y$ leur produit. On cherche à déterminer la loi conjointe de $(X,Y)$. L'univers est $\{-1;1\}^2$, que $X$ prend ses valeurs dans $\{-2,0,2\}$ et $Y$ dans $\{-1,1\}$. Les variables aléatoires étant discrètes, il suffit de déterminer toutes les probabilités $P(X=x\text{  et }Y=y$) pour tout couple $(x,y)\in \{-1;1\}^2$. On a :
 \begin{itemize}
 \item $P(X=2, Y=1)=1/4$(correspond au cas on on tire 1 et 1).
 \item $P(X=2, Y=-1)=0.$
\item  $P(X=0, Y=1)=0.$
\item  $P(X=0, Y=-1)=1/2.$
\item $P(X=-2, Y=1)=1/4.$
\item $P(X=-2, Y=-1)=0.$
 \end{itemize}

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\backslashbox{$X$}{$Y$} & -1& 1 & $P(X=x)$\\\hline
-2 & 1/4& 0 & 1/4\\\hline
0 & 0& 1/2 & 1/2\\\hline
2 & 1/4& 0 & 1/4\\\hline
$P(Y=y)$&1/2&1/2&1 \\\hline
\end{tabular}
\end{center} 
\end{Ex}
\begin{Ex}
Dans une classe, la répartition en fonction de l'age et du genre est :
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\backslashbox{Age}{Genre} & Fille& Garçon & Total\\\hline
18 & 5 & 10& 15 \\\hline
19 & 2 & 6& 8 \\\hline
20 & 0 & 1 & 1 \\\hline
Total&7&17&24 \\\hline
\end{tabular}
\end{center}
On tire au hasard un élève dans la classe.\\
$X$ représente l'age de l'élève.\\
$Y$ représente le genre de l'élève avec la label 0 pour une fille et le label 1 pour un garçon.\\
La loi de probabilité conjointe $(X,Y)$ est déterminé par :
 \begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\backslashbox{$X$}{$Y$} & 0& 1 & $P(X=x)$\\\hline
18 & 5/24& 10/24 & 15/24\\\hline
19 & 2/24& 6/24 & 8/24\\\hline
20 & 0/24& 1/24 & 1/24\\\hline
$P(Y=y)$&7/24&17/24&1 \\\hline
\end{tabular}
\end{center} 

\end{Ex}




%% -----------------------------------------------------------------------------
\subsection{Espérance}
L'espérance mathématique d'une variable aléatoire réelle est la moyenne pondérée par les probabilités d'apparition de chaque valeur. Le théorème de la loi forte des grands nombres démontrera que l'espérance est la valeur que l'on s'attend à trouver, en moyenne, si l'on répète un grand nombre de fois la même expérience aléatoire.
\begin{Df}[espérance d'une variable aléatoire]
Soit $X$ une valeur aléatoire réelle.\\
L'\defi{espérance de $X$} est
\[ E(X) = \sum_{\omega\in\Omega} X(\omega) P(\{\omega\}) \]
\end{Df}

\begin{Th}[formule de transfert]
Si $X$ est une variable aléatoire réelle, alors
\[ E(X) = \sum_{x\in X(\Omega)} x P(X=x). \]
Plus généralement, si $X$ est une variable aléatoire à valeurs dans $E$
 et $f:E\to F$, alors
\[ E(f(X)) =  \sum_{x\in X(\Omega)}  f(x) P(X=x). \]
\end{Th}
\begin{NB}
La formule de transfert permet de  calculer $E(f(X))$ sans avoir à déterminer la loi de $f(X)$.\\
Dans l'exemple du jeu, l'espérance de la variable aléatoire $G(X)$ représente le gain  moyen du joueur. On applique la formule du transfert :
\[E(G(S))=\sum_{s\in \{2,3,\dots,12\}}  G(s) P(S=s)=2P(S=2)-1P(S=7)+2P(S=12)=2\frac{1}{36}-1\frac{6}{36}+2\frac{2}{36}=-\frac{1}{18}.\]
En conclusion, ce jeu n'est pas favorable au joueur.
\end{NB}

\begin{proof}
Soit $X(\Omega)=\{x_1,x_2,\dots,x_n\}$ les valeurs prises par la variables aléatoires.\\
Les événements $X^{-1}(x_1),\dots,X^{-1}(x_n)$ est un système complet d'événements. On a :
\begin{align*}
 E(X) &= \sum_{\omega\in\Omega} X(\omega) P(\{\omega\})\\
 &= \sum_{\omega\in \cup_{i=1}^{n}X^{-1}(x_i)} X(\omega) P(\{\omega\})\\
  &= \sum_{x\in \{x_1,x_2,\dots,x_n\} } \sum_{\omega \in X^{-1}(x)} X(\omega) P(\{\omega\})\\
    &= \sum_{x\in \{x_1,x_2,\dots,x_n\} } \sum_{\omega \in X^{-1}(x)} x P(\{\omega\})\\
    &= \sum_{x\in \{x_1,x_2,\dots,x_n\} }  x \sum_{\omega \in X^{-1}(x)} P(\{\omega\})\\
      &= \sum_{x\in X(\Omega) }  x P(X=x)
\end{align*} 
\end{proof}
\begin{Th}
Soit $X$ et $Y$ deux variables aléatoires indépendantes.\\
Alors \[ E(XY) = E(X) E(Y). \]
\end{Th}
\begin{proof}
On applique le théorème de transfert à la variable aléatoire $f(X,Y)=XY$ d'où
\begin{align*}
 E(XY) &= \sum_{ (x,y)\in X(\Omega)\times Y(\Omega) } xy P(X=x\cap Y=y )\\
       &\overbrace{=}^{\text{indépendance} } \sum_{ (x,y)\in X(\Omega)\times Y(\Omega) } xy P(X=x) P(Y=y)\\
       &= \sum_{ x\in X(\Omega) }  \sum_{ y\in  Y(\Omega) }xy P(X=x) P(Y=y) \\
       &= \sum_{ x\in X(\Omega) } x P(X=x) \sum_{ y\in  Y(\Omega) }y  P(Y=y) \\
       &= E(X)E(Y).
\end{align*} 
\end{proof}
\begin{Df}[Centrée]
Une variable aléatoire est dite \defi{centrée} si son espérance est nulle.
\end{Df}

\begin{Prop}[propriétés de l'espérance]
Soit $X$ et $Y$ deux variables aléatoires réelles et $(a,b)\in\R^2$.
\begin{itemize}
\item
  $E(a) = a$.
\item
  $E(aX+bY) = aE(X)+bE(Y)$.
\item
  Si $P(X\geq 0)=1$, alors $E(X)\geq 0$.
\item
  Si $P(X\leq Y)=1$, alors $E(X)\leq E(Y)$.
\end{itemize}
\end{Prop}
\begin{Ex}[Centrée une variable aléatoire]
Soit $X$ une variable aléatoire.\\
Alors la variable aléatoire $Y=X-E(X)$ est centrée.
\end{Ex}

%
\begin{Prop}[inégalité de Markov]
Soit $X$ une variable aléatoire réelle positive.\\
Pour tout $a > 0$, on a :
\[ P(X\geq a) \leq \frac{E(X)}{a}.\]
\end{Prop}
\begin{proof}

\end{proof}
\subsection{Variance}
La variance est une mesure de la dispersion des valeurs d'une loi de probabilité.
\begin{Df}[variance d'une variable aléatoire]

Soit $X$ une variable aléatoire réelle.
Sa \defi{variance} est $E\left( (X-E(X))^2\right)$ et on la note $V(X)$.
Son \defi{écart-type} est $\sigma(X) =\sqrt{V(X)}$.
\end{Df}
\begin{Prop}[Formule]
Soit $X$ une variable aléatoire réelle.
Pour tout $a>0$, on a
\[ V(X) = E(X^2)-(E(X))^2 \]
\end{Prop}
\begin{proof}

\end{proof}
\begin{Prop}[inégalité de Bienaymé-Tchebychev]

Soit $X$ une variable aléatoire réelle.
Pour tout $a>0$, on a
\[ E( |X-E(X)| \geq a ) \leq \frac{V(X)}{a^2} \]
\end{Prop}
\begin{Df}[covariance de deux variables aléatoires]

Soit $X$ et $Y$ deux variables aléatoires réelles.
Leur \defi{covariance} est $E( (X-E(X)) (Y-E(Y)) )$ et on la note $\mathrm{Cov}(X,Y)$.
\end{Df}
\begin{Prop}[Propriétés]

Soit $X$ et $Y$ deux variables aléatoires réelles.
\begin{itemize}
\item
  $V(aX+b) = a^2V(X)$.
\item
  Si $X$ et $Y$ sont indépendantes, alors $V(X+Y) =V(X)+V(Y)$.
\item
  $Var(X+Y) = Var(X) + Var(Y) + 2\mathrm{Cov}(X,Y)$.
\end{itemize}
\end{Prop}

\begin{Df}[corrélation]

Soit $X$ et $Y$ deux variables aléatoires réelles de variance non nulles.
Leur \defi{coefficient de corrélation} est
\[ \rho(X,Y) = \frac{\mathrm{Cov}(X,Y)}{\sigma(X)\sigma(Y)} \]
\end{Df}


\begin{Prop}[Propriétés]

Soit $X$ et $Y$ deux variables aléatoires réelles de variance non nulles.
\begin{itemize}
\item
  $\rho(X,Y) \in [-1,1]$
\item
  $\rho(X,Y) = ±1$ si et seulement si il existe deux réels $a$ et $b$ tels que l'événement $(Y=aX+b)$ soit certain.
\item
  Si $X$ et $Y$ sont indépendantes, alors $\rho(X,Y) = 0$. On dit qu'elles sont décorrélées.
  La réciproque est fausse.
\end{itemize}
\end{Prop}
%% -----------------------------------------------------------------------------
\subsection{Lois usuelles}

\begin{Df}[loi uniforme]

Une variable aléatoire réelle $X$ suit la \defi{loi uniforme} sur $\{1,2,\dots,n\}$
si 
\begin{enumerate}
\item $X(\Omega)=\{1,2,\dots,n\}$,
\item $\forall k\in \{1,2,\dots,n\}:\quad  P(X=k) = \frac{1}{n}.$ 
\end{enumerate} 
On note $X \hookrightarrow \mathcal{U}(E)$.\\
On a : $E(X)=\frac{n+1}{2}$ et $V(X)=\frac{n^2-1}{2}$.
\end{Df}

\begin{Df}[loi de Bernoulli]
Une variable $X$ à valeurs dans $\{0,1\}$ suit la \defi{loi de Bernoulli} de paramètre $p$
si 
\begin{enumerate}
\item $X(\Omega)=\{0,1\}$,
\item $P(X=1) = p \quad \text{et} \quad P(X=0) = 1-p.$ 
\end{enumerate} 
On note $X \hookrightarrow  \mathcal{B}(p)$.\\
On a : $E(X)=p$ et $V(X)=p(1-p)$.
\end{Df}
\begin{Prop}[Loi indicatrice]
Soit $A$ est un événement de $\Omega$. La variable aléatoire réelle $1_A$ définie par  
$$1_A(\omega) =\begin{cases}1\text{ si }\omega \in A\\0\text{ si }\omega \in \bar A \end{cases}$$
est une variable de Bernoulli de paramètre $p=P(A)$. On l'appelle \defi{loi indicatrice} de l'événement $A$.
\end{Prop}
\begin{Df}[loi binomiale]
Une variable $X$ à valeurs dans $\{0,n\}$ suit la \defi{loi binomiale} de paramètres $n$ et $p$
si
\begin{enumerate}
\item $X(\Omega)=\{0,1,2\dots,12\}$,
\item $\forall k\in\{0,1,\dots,n\},\quad P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}.$ 
\end{enumerate} 
On note $X \hookrightarrow  \mathcal{B}(n,p)$.\\
On a : $E(X)=np$ et $V(X)=np(1-p)$.
\end{Df}
\begin{NB}
Pour $n=1$, on retrouve la loi de Bernouilli de paramètre $p$.
\end{NB}
\begin{Prop}[Loi des tirages avec remise]
Soit $X_1, X_2,\dots, X_n$ $n$ variables aléatoires indépendantes de loi de Bernoulli de même paramètre $p$.\\
Alors $S=X_1+ X_2+\dots+ X_n$ suit une loi binomiale de paramètres $n, p$.\\
En d'autres termes, si l'expérience aléatoire est  une répétition de $n$ épreuves identiques et indépendantes tel que chaque épreuve est une expérience Bernouilli de paramètre  $p$ et si $S$ est égale au nombre de succès des $n$ épreuves de l'expérience, alors $S$  suit une loi binomiale de paramètres $n, p$.\\    
\end{Prop}


%TODO FAIRE LES DEMOS RAJOUTER DES EXEMPLES











 


























\end{document}
